[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Machine Learning verstehen statt nur anwenden",
    "section": "",
    "text": "Über das Buch\nDie Motivation für dieses Buch entstand aus drei Gründen. Erstens wuchs bei mir die Erkenntnis, dass viele kleine und mittelgrosse Unternehmen (KMU) in der Schweiz zwar über grosse Datenmengen verfügen, aber nicht das nötige Knowhow haben, um die Daten zu analysieren und für die Optimierung von Entscheidungsprozessen zu nutzen. Zweitens ist das Thema Machine Learning (ML) und Künstliche Intelligenz (KI) spätestens seit dem Launch von ChatGPT im November 20221 kaum mehr ignorierbar und es geht nun darum, solche Modelle wertschöpfend in Unternehmens- oder Organisationsprozesse zu integrieren. Mit diesem Buch möchte ich einen kleinen Beitrag leisten, den Knowhow Transfer von Fachhochschulen in die Unternehmen und Organisationen zu katalysieren. Drittens sind die meisten Lehrmittel zum Thema auf Englisch verfasst und ich möchte mit einem ausführlichen Lehrmittel in Deutscher Sprache dazu beitragen, dass die Sprachbarriere niemanden daran hindert, in das faszinierende Thema einzutauchen.\nDas Buch versucht, sowohl die klassischen Machine Learning Methoden als auch neueste Entwicklungen im Deep Learning (DL) zu vermitteln. Deep Learning kann als eine Teilmenge des Machine Learnings gesehen werden. Das heisst, jede Deep Learning Methode ist auch eine Machine Learning Methode. Machine Learning umfasst jedoch weitere Methoden, welche nicht dem Deep Learning zugeordnet werden können. Das Gebiet Machine Learning ist wiederum eine Teilmenge der Methoden der Künstlichen Intelligenz. Letztere umfasst wiederum weitere Methoden, welche nicht dem Machine Learning zuzuordnen sind. Abbildung 1 stellt diesen Sachverhalt schematisch dar.\nObwohl das Buch einen anwendungsorientierten Ansatz verfolgt, soll die mathematisch-statistische Intuition hinter den beschriebenen Modellen und Methoden nicht zu kurz kommen. Diese Intuition ist aus meiner Sicht zwingend notwendig, um beurteilen zu können, ob sich ein Modell überhaupt für ein gegebenes Problem eignet und wann ein Modell potentiell nicht funktioniert. Am Schluss geht es nämlich darum, dass wir mit dem Einsatz von Machine Learning einen Mehrwert für ein Unternehmen oder für die Gesellschaft schaffen können. Das erfordert, dass wir uns eingehend und kritisch mit den Modellen und deren Eignung für ein gegebenes Problem auseinander setzen.\nWir werden darum für alle Themen und Modelle die notwendigen mathematischen Grundlagen erarbeiten, so dass wir die zugrunde liegeden Annahmen, die Form sowie die Funktionsweise eines Modells verstehen. Wie es der Titel des Buchs sagt, soll es nämlich darum gehen, Modelle nicht nur anzuwenden, sondern sie eben auch richtig gut zu verstehen.",
    "crumbs": [
      "Über das Buch"
    ]
  },
  {
    "objectID": "index.html#zielgruppe",
    "href": "index.html#zielgruppe",
    "title": "Machine Learning verstehen statt nur anwenden",
    "section": "Zielgruppe",
    "text": "Zielgruppe\nDas Buch richtet sich insbesondere an Fachhochschulstudierende in der deutschsprachigen Schweiz mit einem intrinsischen Interesse an quantitativen Methoden im Allgemeinen und Machine Learning im Besonderen. Vorausgesetzt werden Mathematikkenntnisse auf Stufe Mittelschule (Berufs- oder gymnasiale Matur), d.h. Sie sollten vertraut sein mit den Grundlagen bezüglich mathematischer Funktionen, der Integral- und Differentialrechnung sowie den wichtigsten Resultaten aus der Algebra. Ausserdem gehe ich davon aus, dass Sie bereits eine Einführung in das Thema Statistik besucht haben und Konzepte aus der deskriptiven Statistik (Mittelwert, Median, Varianz, Quantile, etc.) sowie aus der Inferenzstatistik (Verteilungen, statistisches Testen, etc.) bekannt sind.\nBevor Sie sich aber nun Sorgen machen: Kapitel Anhang A — Mathe- und Statistik-Grundlagen enthält eine Einführung in die wichtigsten Mathematik- und Statistikgrundlagen, die nötig sind für das Verständnis von Machine Learning Modellen.\nDa ich mit diesem Buch einen anwendungsorientierten Ansatz verfolge, werden wir auch in das Programmieren einsteigen. Dazu verwenden wir in diesem Buch die Programmiersprache R und für die späteren Kapitel zum Thema Deep learning auch Python. Es werden keine Vorkenntnisse vorausgesetzt. Kapitel Anhang B — R und Python enthält eine kurze Einführung in die Programmiersprachen R und Python und verweist Sie auf weiterführende Ressourcen zum Thema Programmieren. Jedes Modell, das wir uns anschauen werden, ist mit R-Code (oder Python-Code) dokumentiert, so dass Sie lernen, wie die Modelle in der Praxis angewendet werden können.",
    "crumbs": [
      "Über das Buch"
    ]
  },
  {
    "objectID": "index.html#aufbau-des-buchs",
    "href": "index.html#aufbau-des-buchs",
    "title": "Machine Learning verstehen statt nur anwenden",
    "section": "Aufbau des Buchs",
    "text": "Aufbau des Buchs\nDas Buch beginnt mit einer Einführung zum Thema Machine Learning in Kapitel 1  Einführung. Wir lernen verschiedene Definitionen kennen, machen einen kurzen Ausflug in die Geschichte des Machine Learnings und sehen Anwendungsbeispiele.\nDanach ist das Buch in zwei Teile aufgeteilt. Im ersten Teil beginnen wir mit dem Teil des Machine Learnings, den ich klassisches Machine Learning nenne. Dabei lernen wir drei Modellfamilien kennen: lineare Modelle, Entscheidungsbaum-basierte Modelle sowie Support Vector Machines. Ausserdem schauen wir uns in Kapitel 4  ML Pipeline eine typische Pipelines für klassische ML Probleme an. Dieser Teil enthält folgende sechs Kapitel:\n\nKapitel 2  Lineare Regression: Hier erlernen wir die Grundmodelle, um Regressionsprobleme zu lösen. Es sind lineare Modelle, was bedeutet, dass die funktionale Form der Modelle linear von den Parametern des Modells abhängen. Grafisch bedeutet dies, dass ein solches Modell im einfachsten Fall durch eine Gerade beschrieben werden kann.\nKapitel 3  Lineare Klassifikation: In diesem Kapitel lernen wir die Grundmodelle für das Klassifikationsproblem kennen. Diese Modelle führen typischerweise zu einer linearen Entscheidungsgrenze (engl. Decision Boundary) zwischen den verschiedenen Klassen, die wir unterscheiden oder klassifizieren wollen.\nKapitel 4  ML Pipeline: Damit wir ML in der Praxis anwenden können, lernen wir hier die typische ML-Pipeline kennen. Sie werden die Techniken und Methoden kennen lernen, die es braucht, um überhaupt erst an den Punkt zu kommen, um ein ML-Modell rechnen zu können. Oft werden diese Techniken und Methoden unter dem Begriff Preprocessing der Daten zusammengefasst. Doch die Pipeline endet nicht mit dem Rechnen eines ML-Modells. Danach muss ein Modell evaluiert werden und wenn Sie als Analyst:in zufrieden sind, müssen Sie sich Gedanken machen, wie das Deployment des Modells aussehen soll. Das heisst, wie kann Ihr Modell Dritten zur Verfügung gestellt werden?\nKapitel 5  Entscheidungsbäume: Nach den ersten linearen Modellen für das Regressions- und Klassifikationsproblem lernen wir hier ein flexibleres Modell kennen, nämlich den Entscheidungsbaum (engl. Decision Tree). Entscheidungsbäume eignen sich sowohl für das Regressions- als auch für das Klassifikationsproblem. Obwohl sie in realen Projekten typischerweise anderen Modellen unterlegen sind, wenn es um die Vorhersagequalität geht, sind sie trotzdem attraktive Modelle, da sie gut visualisierbar und erklärbar sind.\nKapitel 6  Ensembles: Aufbauend auf den Entscheidungsbäumen aus dem vorherigen Kapitel können sehr mächtige Modelle erstellt werden, die in der Praxis oft mit Modellen aus dem Deep Learning konkurrenzieren können. Weil es sich dabei üblicherweise um eine clevere Aggregierung der Resultate einer grossen Anzahl individueller Entscheidungsbäume handelt, werden diese Modelle Ensembles genannt. Wie die individuellen Entscheidungsbäume eignen sich Ensembles sowohl für das Regressions- als auch für das Klassifikationsproblem.\nKapitel 7  Support Vector Machines: Ein weiteres Modell, das sich sowohl für das Regressions- als auch für das Klassifikationsproblem eignet, sind die Support Vector Machines. Ihre Popularität ist mit dem Aufstieg von Deep Learning etwas verblasst. Es lohnt sich aber immer noch allemal, diese Familie von Modellen kennen zu lernen, insbesondere auch weil sie nicht als Blackbox-Modelle gelten und theoretisch gut fundiert sind.\n\nIn einem zweiten Teil schauen wir uns die modernen Entwicklungen im Gebiet an. Man kann diese grob als Deep Learning beschreiben. Folgende Kapitel sind in diesem zweiten Teil enthalten:\n\nKapitel 8  Artificial Neural Networks: Ab diesem Kapitel steigen wir in das Thema Deep Learning ein. Sie werden die Architektur von einfachen Articial Neural Networks (ANNs) kennen lernen. Ausserdem schauen wir uns in diesem Kapitel den genialen Backpropagation Algorithmus anhand eines einfachen linearen Regressionsproblems an. Dieser Algorithmus ist der Schlüssel für die viel diskutierten Fortschritte im Bereich der künstlichen Intelligenz, weil er das Trainieren von riesigen Modellen überhaupt erst möglich macht.\nKapitel 9  Convolutional Neural Networks: Hier lernen wir sogenannte Convolutional Neural Networks (CNNs) kennen. Sie sind die Basis für die Fortschritte auf dem Gebiet Computer Vision und erlauben beispielsweise Anwendungen im Bereich automatische Gesichtserkennung in Bildern oder Videos.\nKapitel 10  Recurrent Neural Networks: Nach ANNs und CNNs lernen wir hier Recurrent Neural Networks (RNNs) kennen. Diese Modelle bilden die Basis für Probleme, in denen die Daten als Sequenzen vorliegen. Das können einache Zeitreihen (z.B. Börsenkurse) sein, aber auch komplexere Sequenzdaten wie beispielsweise geschriebene oder gesprochene Sprache oder Tonaufnahmen.\nKapitel 11  Transformers: Hier schauen wir uns die Architektur an, die moderne LLMs wie ChatGPT oder Claude überhaupt erst möglich machte, nämlich die Transformer Architektur. Eine wichtige Komponenten hierbei ist die sogenannte Attention, deren Funktionsweise wir uns im Detail anschauen werden. Nach dem Lesen dieses Kapitels sollten Sie ein grundlegendes Verständnis für die Funktionsweise von Modellen wie Chat-GPT haben.\n\nDer Anhang enthält die mathematisch-statistischen Grundlagen sowie eine Einführung in die Programmierung in R und Python:\n\nAnhang A — Mathe- und Statistik-Grundlagen: Wichtigste Mathe- und Statistikgrundlagen, die für das Verständnis der Modelle elementar sind.\nAnhang B — R und Python: Einführung in das Programmieren mit R und Python sowie Überblick über die wichtigsten R-Packages, die wir verwenden.",
    "crumbs": [
      "Über das Buch"
    ]
  },
  {
    "objectID": "index.html#weiterführende-literatur",
    "href": "index.html#weiterführende-literatur",
    "title": "Machine Learning verstehen statt nur anwenden",
    "section": "Weiterführende Literatur",
    "text": "Weiterführende Literatur\nEin grosser Teil des vorliegenden Buchs baut auf bestehenden Büchern zum Thema Machine Learning und Deep Learning auf. Ich werde im Buch immer wieder auf die Quellen verweisen. Die wichtigsten Referenzen für dieses Buch sind folgende:\n\nGareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani. (2021). An Introduction to Statistical Learning: with Applications in R. New York, NY: Springer. 2nd Edition.\nAurélien Géron. (2022). Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems. Sebastopol, CA: O’Reilly Media Inc. 3rd Edition.\nKevin P. Murphy. (2022). Probabilistic Machine Learning: An Introduction. Cambridge, MA: The MIT Press. 1st Edition.\nKevin P. Murphy. (2023). Probabilistic Machine Learning: Advanced Topics. Cambridge, MA: The MIT Press. 1st Edition.\nAnil Ananthaswamy. (2024). Why machines learn: The elegant math behind modern AI. New York, NY: Dutton.\nChristopher M. Bishop, Hugh Bishop. (2024). Deep Learning: Foundations and Concepts. Cham, Switzerland: Springer International Publishing. 1st Edition.\n\nDie ersten beiden Referenzen sowie das populärwissenschaftliche Buch von Anil Ananthaswamy sind einführende Texte und können problemlos parallel zum vorliegenden Buch gelesen werden. Die Lehrbücher von Kevin Murhpy sowie von Chris und Hugh Bishop sind fortgeschrittene Texte und ich empfehle, sie erst nach dem vollständigen Verständnis des vorliegenden Buchs oder der anderen drei Referenzen zu lesen.",
    "crumbs": [
      "Über das Buch"
    ]
  },
  {
    "objectID": "index.html#lizenz",
    "href": "index.html#lizenz",
    "title": "Machine Learning verstehen statt nur anwenden",
    "section": "Lizenz",
    "text": "Lizenz\nDas vorliegende Buch ist unter der Lizenz CC BY-NC-SA 4.0 DEED (Namensnennung, nicht-kommerziell, Weitergabe unter gleichen Bedingungen 4.0 International) lizenziert.",
    "crumbs": [
      "Über das Buch"
    ]
  },
  {
    "objectID": "index.html#kontakt",
    "href": "index.html#kontakt",
    "title": "Machine Learning verstehen statt nur anwenden",
    "section": "Kontakt",
    "text": "Kontakt\nFür Fragen und Anregungen zum Buch stehe ich gerne zur Verfügung:\nMartin Sterchi\nRiggenbachstrasse 16\n4600 Olten\nmartin.sterchi@fhnw.ch",
    "crumbs": [
      "Über das Buch"
    ]
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Machine Learning verstehen statt nur anwenden",
    "section": "",
    "text": "https://openai.com/index/chatgpt/↩︎",
    "crumbs": [
      "Über das Buch"
    ]
  },
  {
    "objectID": "01_intro.html",
    "href": "01_intro.html",
    "title": "1  Einführung",
    "section": "",
    "text": "1.1 Was ist Machine Learning? Eine kurze Geschichte und Definitionen.\nIn diesem Kapitel geht es darum zu verstehen, was Machine Learning überhaupt ist, warum es nützlich sein kann und was typische Anwendungsfälle von ML sind. Wir werden ausserdem verschiedene Unterkategorien von ML kennen lernen und uns eine kleine Taxonomie erarbeiten. Zum Schluss schauen wir uns den ersten ganz wichtigen Meilenstein im ML an: das Perceptron. Dabei lernen wir auch gleich ein paar wichtige mathematische Grundlagen kennen.\nIm Prinzip geht die Geschichte des MLs weit zurück, nämlich zu den Anfängen der Statistik. Viele Modelle, die heutzutage im ML angewendet werden sind nämlich eigentlich von Statistiker:innen erfundene Modelle. Die Geschichte des MLs und der Statistik sind darum eng miteinander verknüpft. Einen eigentlichen Startpunkt des MLs könnte man vielleicht in den 1950er Jahren ausmachen. Einerseits fand 1956 das sagenumwobene Dartmouth Summer Research Project on Artificial Intelligence1 statt, an dem alle wichtigen Grössen aus dem Gebiet zu dieser Zeit teilnahmen. Der Begriff Artificial Intelligence wurde an diesem Anlass erstmal erwähnt. Andererseits hat Frank Rosenblatt2 ein Jahr später das sogenannte Perceptron und einen dazugehörigen Lernalgorithmus eingeführt (dazu später mehr).\nDanach blieb es aber rund 20 Jahre relativ ruhig bis die Forschung im Bereich Machine Learning so richtig Fahrt aufnahm. Der Hauptgrund dafür war, dass das Perceptron nur für linear separierbare Probleme (auch hierzu später mehr) funktionierte und darum das Interesse daran bald abflachte.\nEin grosser Schub für die Entwicklung von ML ging vom Aufkommen von extrem grossen Datenmengen (Big Data) und dem Internet aus. Das führte nämlich dazu, dass sich immer mehr Leute aus den Fachbereichen Informatik und Computer Science mit dem Thema ML befassten und effiziente Hard- und Software sowie algorithmische Kniffs und Tricks beisteuerten. Ausserdem ermöglichte das Internet den Zugang zu gewaltigen Datenmengen an Bildern, Videos, Klicks, etc. - denken Sie beispielsweise nur schon an die Informationen, die jede:r von uns tagtäglich im Internet hinterlässt. Diese Entwicklungen führten unter anderem zur Entwicklung der ImageNet Challenge3, welche die Entwicklungen im Bereich Computer Vision (maschinelles Sehen) katalysierten.\nEin weiterer Schub für das Machine Learning war (und ist) zudem die immer besser werdende Rechenleistung von Computern, insbesondere der Grafikkarten (engl. Graphics Processing Units oder GPUs), welche für schnelle Matrix- und Vektoroperationen verwendet werden können. All diese Entwicklungen haben sich im November 2022 kulminiert in der erstmaligen breiten öffentlichen Wahrnehmung von sogenannten Large Language Models wie ChatGPT.\nNachdem wir einen ersten groben Überblick über die Geschichte des MLs erhalten haben, wollen wir uns nun überlegen, was ML denn genau ist. Wie der Name sagt, geht es im Machine Learning darum, dass eine Maschine (oder präziser, ein Computer) aus einem gegebenen Datensatz automatisch Muster lernt, ohne dass ein Mensch dem Computer (explizit) sagen muss, was er lernen soll. Der Mensch gibt jedoch dem Computer die Rahmenbedingungen für das automatische Lernen vor.\nDie erlernten Muster sind selbstverständlich nur nützlich, wenn sie genereller Natur sind und auch zukünftigen Beobachtungen zugrunde liegen. Beispiel: ein Spital hat während der Corona Pandemie ein Modell trainiert, um den täglichen Pflegebedarf je nach Wochentag, Saison, und weiteren Indikatoren vorherzusagen. Das Modell funktioniert nun nach der Pandemie aber nicht wunschgemäss und prognostiziert in der Tendenz einen zu hohen Pflegebedarf. Das Problem ist, dass die erlernten Muster nicht gut auf eine Zeit nach der Pandemie generalisierbar sind. Mit anderen Worten: die Trainingsdaten waren nicht repräsentativ genug. ML-Modelle sollen also generell gültige Muster in den Daten erlernen.\nBevor wir etwas konkreter anschauen, wie genau ein Computer automatisch aus Daten lernen kann, schauen wir uns die Definitionen von zwei Experten im Gebiet ML an:\nZusammenfassend lässt sich sagen, dass wir mit ML dem Computer die Möglichkeit geben, automatisch und selbständig aus Daten generalisierbare Muster zu lernen. Nichtsdestotrotz braucht es Sie als ML-Expert:in, und zwar wie folgt:\nEs handelt sich bei dieser Vorgehensweise um eine sehr allgemeine Beschreibung des ML Prozesses. Wie diese drei Schritte konkret funktionieren, werden Sie in den nachfolgenden Kapiteln dieses Buchs erfahren.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einführung</span>"
    ]
  },
  {
    "objectID": "01_intro.html#was-ist-machine-learning-eine-kurze-geschichte-und-definitionen.",
    "href": "01_intro.html#was-ist-machine-learning-eine-kurze-geschichte-und-definitionen.",
    "title": "1  Einführung",
    "section": "",
    "text": "HinweisDefinitionen\n\n\n\n“[Machine Learning is the] field of study that gives computers the ability to learn without being explicitly programmed.” Arthur Samuel, 1959 (zitiert in Géron 2022, p. 4)\n“Machine Learning is the science (and art) of programming computers so they can learn from data.” Aurélien Géron (Géron 2022, p. 4)\n\n\n\n\nBevor wir ML verwenden können, um Muster in Daten zu lernen, müssen wir uns für ein konkretes Modell entscheiden. ML Modelle können unterschiedlich flexibel sein und es liegt im Ermessen von Ihnen, wie flexibel das Modell sein soll. Sie müssen bei der Wahl des Modells die Komplexität des Problems berücksichtigen. Grundsätzliche gilt bei der Wahl des Modells, dass flexiblere Modelle komplexere Sachverhalte abbilden können. Ein zu flexibles Modell kann aber schnell zu Overfitting führen, doch dazu später mehr. Dieser erste Schritt wird im Fachjargon typischerweise Modellwahl (engl. Model Selection) genannt.\nSobald Sie das Modell ausgewählt haben, übergeben Sie dem Computer (etwas vereinfacht gesagt) das Modell, einen Datensatz sowie einen Lernalgorithmus. Nun hat der Computer alle Zutaten, um automatisch zu lernen. Doch was lernt er eigentlich? Der Computer lernt die Parameter Ihres gewählten Modells, so dass das Modell sich optimal an die Daten anpasst. Dieser Schritt wird im Fachjargon Modelltraining (engl. Model Training oder Model Fitting) genannt.\nFalls Sie mit dem erlernten Modell zufrieden sind, können Sie es nun entweder dazu verwenden Vorhersagen zu machen oder um Zusammenhänge in den Daten zu interpretieren und daraus wertvolle Einsichten gewinnen. Dieser Schritt wird im Fachjargon als Modellinferenz (engl. Model Inference) zusammengefasst. Typischerweise sind Sie in der Realität mit dem ersten erlernten Modell allerdings noch nicht zufrieden und gehen zurück zu Schritt 1 und wählen ein anderes Modell.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einführung</span>"
    ]
  },
  {
    "objectID": "01_intro.html#wann-macht-es-sinn-ml-einzusetzen",
    "href": "01_intro.html#wann-macht-es-sinn-ml-einzusetzen",
    "title": "1  Einführung",
    "section": "1.2 Wann macht es Sinn ML einzusetzen?",
    "text": "1.2 Wann macht es Sinn ML einzusetzen?\nEin ML Modell zu trainieren (zweiter Schritt oben) kann viel Zeit und Geld kosten. Zum Beispiel müssen Sie unter Umständen überhaupt erst die Daten sammeln (oder von einem Datendienstleister kaufen), um ein Modell trainieren zu können. Oder das Projekt ist so komplex, dass Sie als Analyst:in unzählige Stunden benötigen, um die Daten überhaupt erst in eine Form zu bringen, die es erlaubt ein Modell zu trainieren. Für neuartige DL Modelle oder Generative KI kann das Trainieren eines Modells durch den reinen Stromverbrauch bzw. die vom Cloud-Betreiber in Rechnung gestellten Kosten so hoch sein, dass sich Ihr ursprüngliches Vorhaben nicht mehr lohnt. Es ist also ungemein wichtig, dass Sie sich vor Projektbeginn gut überlegen, ob ML für Ihr vorliegendes Problem überhaupt Sinn macht und einen Mehrwert generieren kann.\nFolgende Daumenregeln (siehe auch Géron 2022, p. 7) können Ihnen dabei helfen, zu entscheiden, ob ML für Ihr Projekt Sinn macht:\n\nIhr Problem entspricht einem standard ML-Problem, das bereits mehrfach gelöst wurde und für das es sogenannte “off-the-shelf” Lösungen gibt. Beispiel: Sie wollen das Sentiment (positive vs. negative Grundhaltung) von Social Media Posts über Ihr Unternehmen automatisch klassifizieren. Dazu gibt es viele vortrainierte Modelle, die teilweise open-source sind und frei verwendet werden können.\nDer manuelle Arbeitsaufwand ist sehr gross, wenn das Problem durch Menschen gelöst werden soll. Das Problem ist aber ansonsten klar strukturiert und benötigt keinen grossen kognitiven Einsatz eines Menschen. Beispiel: In den Post-Verteilzentren werden die von Hand geschriebenen Postleitzahlen (PLZ) bzw. Adressen problemlos von ML Modellen erkannt und die Briefe und Pakete entsprechend sortiert.\nKomplexe Probleme, in denen ein Mensch keinen Überblick hat, weil so grosse und komplexe Datenmengen vorhanden sind. Wir Menschen haben grosse Mühe damit, in Rohdaten (reinen Datentabellen) irgendwelche Muster zu erkennen. In diesem Fall können wir entweder versuchen, die Daten zu visualisieren oder mithilfe von ML Zusammenhänge zu lernen, die wir sonst nicht erkennen könnten.\n\nEin illustratives Beispiel für den dritten Fall ist das Anscombe Quartett4, das vier kleine Stichproben mit jeweils elf Datenpunkten enthält. Jeder Datenpunkt wird durch eine \\(x\\) und eine \\(y\\) Variable beschrieben. Die vier \\(x\\)- sowie die vier \\(y\\)-Variablen haben identische Mittelwerte:\n\n\n   x1 x2 x3 x4    y1   y2    y3    y4\n1  10 10 10  8  8.04 9.14  7.46  6.58\n2   8  8  8  8  6.95 8.14  6.77  5.76\n3  13 13 13  8  7.58 8.74 12.74  7.71\n4   9  9  9  8  8.81 8.77  7.11  8.84\n5  11 11 11  8  8.33 9.26  7.81  8.47\n6  14 14 14  8  9.96 8.10  8.84  7.04\n7   6  6  6  8  7.24 6.13  6.08  5.25\n8   4  4  4 19  4.26 3.10  5.39 12.50\n9  12 12 12  8 10.84 9.13  8.15  5.56\n10  7  7  7  8  4.82 7.26  6.42  7.91\n11  5  5  5  8  5.68 4.74  5.73  6.89\n\n\nSelbst in diesem kleinen Datensatz ist es für uns Menschen äusserst schwierig, irgendwelche Muster zu erkennen. Erst eine einfache Visualisierung der vier Stichproben mithilfe eines Streudiagramms zeigt die Muster sowie die Unterschiede zwischen den vier Stichproben deutlich auf:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einführung</span>"
    ]
  },
  {
    "objectID": "01_intro.html#anwendungsfälle-von-ml",
    "href": "01_intro.html#anwendungsfälle-von-ml",
    "title": "1  Einführung",
    "section": "1.3 Anwendungsfälle von ML",
    "text": "1.3 Anwendungsfälle von ML\nIn diesem Abschnitt stelle ich erfolgreiche Anwendungsfälle von ML vor. Einige davon treffen Sie womöglich tagtäglich in Ihrem Alltag an:\n\nSpam Filter sind ein frühes Beispiel einer erfolgreichen Anwendung von ML. Ein Modell entscheidet dabei automatisch aufgrund der Inhalte einer Email, des Betreffs sowie des Absenders, ob es sich um eine Spam oder eine sogenannte Ham Email (unproblematische Email) handelt. Falls Sie gängige Email Software verwenden, dann arbeitet im Hintergrund ein Spam Filter daran, Sie vor lästigen Emails zu schützen.\nEin grosser Teil des wirtschaftlichen Erfolgs von Google basiert auf der Idee, dass aufgrund der Suchhistorie hervorgesagt werden kann, welche Nutzerin oder welcher Nutzer mit welcher Wahrscheinlichkeit eine bestimmte Werbung anklickt. Dies erlaubt Google für jede Nutzer:in die Werbung mit den höchsten “Erfolgschancen” zu schalten. Da jeder Klick Einnahmen generiert, ist es für das Geschäftsmodell von Google entscheidend, dass möglichst viele Klicks stattfinden.\nEin grosser Bereich des MLs und speziell des DLs befasst sich mit Computer Vision. Dabei geht es darum, das Hauptmotiv von Bildern zu klassifizieren (z.B. zeigt ein Bild ein Tier oder einen Menschen?), Objekte in Bildern zu entdecken (z.B. enthält das Bild eine Person?) und das entdeckte Objekt dann auch zu klassifizieren (z.B. handelt es sich bei der Person um XY?). Als konkreteres Beispiel können Sie sich einen Industriebetrieb vorstellen, welcher ein Computer Vision Modell einsetzen möchte, um den Abnützungsgrad der von ihnen produzierten Werkzeuge automatisch zu erkennen und den Kundinnen und Kunden den optimalen Ersatzzeitpunkt für das Werkzeug vorhersagen zu können.\nÄhnlich wie im vorherigen Beispiel gibt es bereits viele Anwendungen im öffentlichen Verkehr, in denen es um Predictive Maintenance geht. Z.B. kann der optimale Wartungszeitpunkt für eine Weiche oder einen Gleisabschnitt aufgrund einer Vielzahl an Indikatoren und Messungen vorhergesagt werden.\nEin grosses Einsatzgebiet für ML ergibt sich im Finanzsektor durch das automatische Erkennen von potentiell betrügerischen Transaktionen. Falls Sie auch schon mal eine Kreditkartentransaktion direkt am Telefon einer Kundenberaterin oder einem Kundenberater bestätigen mussten, dann ist es wahrscheinlich, dass Ihre Transaktion von einem ML System zur manuellen Überprüfung geflaggt wurde. In diesem Zusammenhang spricht man manchmal auch vom Erkennen von Anomalien (engl. Anomaly Detection).\nSogenannte Recommender Systems sind insbesondere in Online Verkaufspunkten von grossem Nutzen. Betreiben Sie beispielsweise einen grossen Onlinehandel, dann wollen Sie Ihren Kundinnen und Kunden Produkte zum Kauf vorschlagen. Dazu verwenden Sie ein Modell, das basierend auf der Ähnlichkeit zwischen Kundinnen und Kunden potentiell interessante Produkte vorschlägt.\nDie rasanten Entwicklungen im Bereich Natural Language Processing (NLP) in den letzten 10 Jahren haben viele neue und interessante Anwendungsgebiete zutage gefördert. Zum Beispiel eignen sich Large Language Models (LLMs) als erste Anlaufstelle für Kundinnen und Kunden (automatisierter Kundenservice). LLMs werden vermutlich aber auch immer mehr in internen Prozessen in Unternehmen eingesetzt, z.B. um komplexe Dokumente zusammenzufassen oder Sitzungsprotokolle zu erstellen.\n\nDie obige Liste ist bei weitem nicht komplett und die Entwicklungen im Bereich ML sind aktuell so rasant, dass jeden Tag eine grosse Zahl von neuen ML-basierten Produkten und Dienstleistungen auf den Markt kommen.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einführung</span>"
    ]
  },
  {
    "objectID": "01_intro.html#supervised-vs.-unsupervised-learning",
    "href": "01_intro.html#supervised-vs.-unsupervised-learning",
    "title": "1  Einführung",
    "section": "1.4 Supervised vs. Unsupervised Learning",
    "text": "1.4 Supervised vs. Unsupervised Learning\nDen Unterschied zwischen dem Supervised Learning und dem Unsupervised Learning können wir am besten erklären, indem wir uns mit ein paar mathematischen Grundlagen des Machine Learnings befassen. Keine Sorge, diese Grundlagen sind sehr einfach, aber versuchen Sie, diese bereits gut zu verstehen, denn wir bauen später darauf auf.\nIm Supervised Learning haben wir einerseits sogenannte Input-Daten und andererseits einen Output, den wir vorhersagen wollen. Für die Input-Daten gibt es ganz viele verschiedene Begriffe, die synonym verwendet werden: z.B. Features, unabhängige Variablen, Attribute, Prädiktoren. Dasselbe gilt für den Output, hier gibt es folgende Synonyme: Zielvariable, abhängige Variable, Label, oder auch einfach \\(y\\). Unsere Konvention hier ist aber folgende: es gibt Input-Daten (oder Input-Variablen) und einen Output (oder Output-Variable). Im Unsupervised Learning haben wir lediglich Input-Daten und keinen Output, doch dazu später etwas mehr. Wir formalisieren erstmal die Konzepte Input-Daten und Output.\n\n1.4.1 Input-Daten\nDie Input-Daten für eine Beobachtung \\(i\\) schreiben wir mathematisch wie folgt:\n\\[\n\\mathbf{x}_i=\\begin{pmatrix} x_{i1} \\\\ x_{i2} \\\\ \\vdots \\\\ x_{ip} \\end{pmatrix},\n\\] Diese Notation bedarf ein paar Erklärungen:\n\nDen Index \\(i\\) brauchen wir, um die verschiedenen Beobachtungen zu kennzeichnen. \\(i\\) kann eine Ganzzahl zwischen \\(1\\) und \\(n\\) annehmen, wobei \\(n\\) die Anzahl Beobachtungen im Datensatz bezeichnet. Wenn wir zum Beispiel etwas über die Input-Daten der dritten Beobachtung sagen wollen, dann können wir die Notation \\(\\mathbf{x}_3\\) verwenden.\nFür jede Beobachtung \\(i\\) haben wir insgesamt \\(p\\) Variablen, welche die verschiedenen Attribute einer Beobachtung enthalten. \\(x_{i1}\\) bezeichnet also die erste Variable der i-ten Beobachtung, \\(x_{i2}\\) die zweite Variable der i-ten Beobachtung und \\(x_{ip}\\) die p-te (letzte) Variable der i-ten Beobachtung.\nWas Sie oben sehen, ist \\(\\mathbf{x}_i\\) aus mathematischer Sicht ein Spaltenvektor. Mit diesem Spaltenvektor können wir die Input-Daten einer Beobachtung kompakt darstellen können.\n\n\\(\\mathbf{x}_i\\) bezeichnet nur die beobachteten Input-Variablenwerte für die i-te Beobachtung. Wenn wir die beobachteten Input-Variablenwerte aller \\(n\\) Beobachtungen kompakt darstellen möchten, dann können wir das mit einer Matrix tun. Dazu müssen wir die Input-Variablen für jede Beobachtung \\(i\\) zeilenweise in einer Matrix anordnen:\n\\[\n\\mathbf{X} = \\begin{pmatrix}\nx_{11} & x_{12} & \\cdots & x_{1p}\\\\\nx_{21} & x_{22} & \\cdots & x_{2p}\\\\\n\\vdots & \\cdots & \\ddots & \\vdots\\\\\nx_{n1} & x_{n2} & \\cdots & x_{np}\\\\\n\\end{pmatrix}\n\\]\nDie erste Zeile enthält die Input-Variablen für die erste Beobachtung, die zweite Zeile die Input-Variablen für die zweite Beobachtung, usw.\n\n\n1.4.2 Output\nNeben den Input-Daten haben wir im Supervised Learning aber wie erwähnt auch einen Output und den bezeichnen wir üblicherweise mit \\(y_i\\). Auch hier hilft uns der Index \\(i\\) dabei, die Beobachtungen eindeutig zu kennzeichnen. In den meisten Fällen ist \\(y_i\\) ein sogenannter Skalar, also einfach eine Zahl. Darum schreiben wir es nicht in fetter Schrift wie oben, denn diese ist meist für Vektoren oder Matrizen reserviert.\nAuch hier können wir die Outputwerte aller \\(n\\) Beobachtungen kompakt zusammenfassen und zwar als Vektor\n\\[\n\\mathbf{y}=\\begin{pmatrix} y_{1} \\\\ y_{2} \\\\ \\vdots \\\\ y_{n} \\end{pmatrix}.\n\\]\n\nFrage\nStellen Sie sich vor, wir versuchen mithilfe eines Datensatzes von 5000 getätigten Kreditkartentransaktionen ein Modell zu trainieren, das vorhersagen kann, ob es sich bei einer gegebenen Transaktion um eine betrügerische Transaktion handelt oder nicht. Jede Transaktion in Ihrem Datensatz entspricht einer Beobachtung \\(i\\). Der Output \\(y_i\\) in diesem Beispiel ist eine kategorische Variable, die wir als \\(y_i \\in \\{0,\\;1\\}\\) beschreiben können, wobei 0 keinen Betrug und 1 Betrug bezeichnet. Ausserdem haben Sie folgende Input-Daten:\n\\[\n\\mathbf{x}_i=\\begin{pmatrix}\n\\text{Transaktionsbetrag} \\\\\n\\text{Land des Zahlungsempfaengers} \\\\\n\\text{Zeitstempel der Transaktion}\n\\end{pmatrix}\n\\] Welche Werte nehmen in diesem Beispiel \\(n\\) und \\(p\\) an?\n\n\\(n = 100,\\ p = 3\\)\n\\(n = 5000,\\ p = 3\\)\n\\(n = 3,\\ p = 5000\\)\n\n\\(n = 100,\\ p = 4\\)\n\n\n\n\n\n\n\nTippLösung\n\n\n\n\n\nDie richtige Antwort ist b.\nWir haben \\(n = 5000\\) Beobachtungen und \\(p = 3\\) Variablen.\n\n\n\nDie \\(n\\) Beobachtungen, die für das Training eines Modells zur Verfügung stehen werden meist Trainingsdaten oder Trainingset genannt.\n\n\n\n1.4.3 Taxonomie des Machine Learnings\nBeim Supervised Learning geht es um ML Probleme, in denen sowohl Input-Daten als auch ein Output vorhanden ist. Ziel beim Supervised Learning ist es, ein Modell zu trainieren, das basierend auf den Input-Daten möglichst gute Vorhersagen für den Output macht. Es geht also hier um Vorhersageprobleme. In einem gewissen Sinn ist der Output die überwachende Instanz (engl. Supervisor), welche den Lernprozess des Modells kontrolliert.\nEtwas formaler und mit einem probabilistischen Hut auf kann man Supervised Learning auch wie folgt beschreiben: wir nehmen an, dass die vorliegenden Daten \\((\\mathbf{X},\\,\\mathbf{y})\\) gezogen wurden aus einer wahren, aber unbekannten Verteilung, die wir als \\(P(\\mathbf{X},\\,\\mathbf{y})\\) beschreiben. Im Supervised Learning geht es nun darum diese gemeinsame Verteilung \\(P(\\mathbf{X},\\,\\mathbf{y})\\) mithilfe der vorliegenden Daten möglichst gut zu schätzen. Wählen wir ein Modell, das diese gemeinsame Wahrscheinlichkeit direkt modelliert, dann sprechen wir von einem generativen Modell. Oft versucht man sich jedoch das Leben einfacher zu machen, indem man \\(P(\\mathbf{y}\\mid\\mathbf{X})\\) modelliert. In diesem Fall spricht man von diskriminativen Modellen. Wir werden in späteren Kapiteln auf diese Unterscheidung zurückkommen. Wichtig: fast jedes Modell macht irgendwelche vereinfachenden Annahmen, um entweder ein generatives oder ein diskriminatives Modell zu rechnen.\n\nFrage\nWas passiert, wenn \\(\\mathbf{X}\\) und \\(\\mathbf{y}\\) (statistisch) unabhängig sind? Macht es Sinn, in diesem Fall ein Modell aus dem Supervised Learning zu lernen?\n\n\n\n\n\n\nTippLösung\n\n\n\n\n\nWenn \\(\\mathbf{X}\\) und \\(\\mathbf{y}\\) (statistisch) unabhängig sind, dann kann die gemeinsame Wahrscheinlichkeit (Verteilung) geschrieben werden als \\(P(\\mathbf{X},\\,\\mathbf{y}) = P(\\mathbf{X}) \\cdot P(\\mathbf{y})\\).\nDie bedingte Wahrscheinlichkeit \\(P(\\mathbf{y}\\mid\\mathbf{X})\\) ist in diesem Fall: \\[\nP(\\mathbf{y}\\mid\\mathbf{X}) = \\frac{P(\\mathbf{X},\\,\\mathbf{y})}{P(\\mathbf{X})} = \\frac{P(\\mathbf{X}) \\cdot P(\\mathbf{y})}{P(\\mathbf{X})} = P(\\mathbf{y})\n\\]\nDas bedeutet, dass wir aus \\(\\mathbf{X}\\) nichts über \\(\\mathbf{y}\\) lernen können und Supervised Learning in diesem Fall keinen Sinn macht.\n\n\n\nIm Gegensatz zum Supervised Learning haben wir im Unsupervised Learning nur Input-Daten und keinen Output. Im Unsupervised Learning geht es darum, aus den Input-Daten interessante Muster zu lernen, welche für bessere unternehmerische Entscheidungen verwendet werden können. Ein einfaches Beispiel ist das Clustering von Kundinnen und Kunden eines Unternehmens in ähnliche Kundengruppen, so dass die verschiedenen Kundengruppen gezielter mit Marketingaktionen angesprochen werden können. Techniken, um komplexe Datensätze zu visualisieren, werden typischerweise auch zum Unsupervised Learning gezählt. Im Unsupervised Learning geht es darum, Modelle für \\(P(\\mathbf{X})\\) zu finden und zu rechnen.\nEtwas vereinfacht gesagt, sind ein grosser Teil der Modelle, die wir der Generativen KI zusprechen, nichts anderes als Modelle, die \\(P(\\mathbf{X})\\) so gut wie möglich zu beschreiben versuchen. \\(\\mathbf{X}\\) kann man sich als grosse Menge Text oder eine grosse Anzahl von Bildern vorstellen. Wenn wir nun also Text von einem LLM generieren lassen, dann ist das im Grunde nichts anderes als aus der gelernten Verteilung, die \\(P(\\mathbf{X})\\) approximiert, zu samplen.\nNeben dem Supervised und dem Unsupervised Learning gibt es noch eine dritte Kategorie von Machine Learning, nämlich das Reinforcement Learning (RL). Dieser Kategorie gehören Modelle an, die (virtuelle) Agenten so trainieren, dass sie langfristig möglichst optimal handeln. Das bisher bekannteste Beispiel aus dem RL ist Googles AlphaGo Agent, welcher den menschlichen Go Weltmeister im Jahr 2017 schlug.5 Reinforcement Learning ist aber auch eine wichtige Komponente in der Optimierung von grossen Sprachmodellen wie ChatGPT. In einer ersten Fassung dieses Buchs werden wir uns nicht (oder nur am Rande) mit RL befassen.\nDie Unterscheidung zwischen den drei Arten von Machine Learning ist im oberen Teil der Abbildung 1.1 visualisiert:\n\n\n\n\n\n\nAbbildung 1.1: Die verschiedenen Kategorien des Machine Learnings und deren Hierarchie.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einführung</span>"
    ]
  },
  {
    "objectID": "01_intro.html#regression-vs.-klassifikation",
    "href": "01_intro.html#regression-vs.-klassifikation",
    "title": "1  Einführung",
    "section": "1.5 Regression vs. Klassifikation",
    "text": "1.5 Regression vs. Klassifikation\nIn der Kategorie des Supervised Learnings unterscheiden wir weiter zwischen Regressions- und Klassifikationsproblemen (siehe auch Abbildung 1.1).\nBeim Regressionsproblem ist der Output eine stetige Variable (Intervall- oder Verhältnisskalierung), d.h. die Variable enthält reelle (numerische) Werte. Mathematisch schreibt man dies als \\(y_i \\in \\mathbb{R}\\), wobei \\(\\mathbb{R}\\) die Menge der reellen Zahlen beschreibt.\nBeim Klassifikationsproblem ist der Output bzw. die Zielvariable eine kategorische Variable (Nominal- oder Ordinalskalierung). Mathematisch schreibt man dies als \\(y_i \\in \\{1, \\dots, C\\}\\), wobei \\(C\\) die Anzahl Kategorien beschreibt. Wenn wir nur \\(C=2\\) Kategorien haben wie im Beispiel oben mit \\(y_i \\in \\{0, 1\\}\\), sprechen wir von einem binären Klassifikationsproblem. Falls \\(C&gt;2\\) sprechen wir vom mehrklassigen (engl. multiclass) Klassifikationsproblem.\n\nFrage\nWelche der folgenden Probleme sind Regressionsprobleme?\n\nVorhersage des Lohns der/des Leiter:in eines Unternehmens basierend auf Profit, Marktkapitalisation, Anzahl Mitarbeitender, sowie Sektor, in dem das Unternehmen tätig ist.\nBasierend auf der aktuellen Marktlage und weiteren wirtschaftlichen Aspekten wollen Sie den morgigen Preis einer bestimmten Aktie vorhersagen.\nVorhersage ob eine Person, welche ein bestimmtes Youtube Video schauen will, volljährig ist oder nicht.\nEine Bank möchte mithilfe von historischen Daten vorhersagen, ob ein bestimmter Kunde zahlungsunfähig wird oder nicht.\nEin Detailhandelsunternehmen möchte vorhersagen, ob eine Kundin ein Produkt aus der Kategorie A, B, C, oder kein Produkt kauft.\nVorhersage von Hauspreisen basierend auf Attributen wie der Grösse, Anzahl Zimmer, Seeblick (ja/nein), Steuerlast, etc.\nEin Unternehmen lanciert ein neues Produkt und schätzt anhand von Konkurrenzprodukten, ob das eigene Produkt ein Erfolg wird oder nicht.\n\n\n\n\n\n\n\nTippLösung\n\n\n\n\n\nKorrekt sind die Antworten a, b und f.\nBei allen anderen Antworten handelt es sich um Klassifikationsprobleme.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einführung</span>"
    ]
  },
  {
    "objectID": "01_intro.html#parametrische-vs.-nicht-parametrische-modelle",
    "href": "01_intro.html#parametrische-vs.-nicht-parametrische-modelle",
    "title": "1  Einführung",
    "section": "1.6 Parametrische vs. nicht-parametrische Modelle",
    "text": "1.6 Parametrische vs. nicht-parametrische Modelle\nEin ML Modell gehört entweder der Familie parametrischer Modelle oder der Familie nicht-parametrischer Modelle an. Dabei spielt es keine Rolle, ob wir mit dem Modell ein Regressions- oder ein Klassifikationsproblem lösen wollen.\nWomöglich sind Sie in Ihrer Ausbildung bereits parametrischen Modellen begegnet, denn das einfache lineare Regressionsmodell ist ein typisches Beispiel für ein parametrisches ML Modell. Das Modell ist vollkommen charakterisiert durch die beiden lernbaren Parameter \\(w_0\\) und \\(w_1\\)6 und kann wie folgt (mathematisch) aufgeschrieben werden:\n\\[\n\\hat{y}_i = f(x_i)=w_0 + w_1 \\cdot x_i\n\\]\nWenn Ihnen der obige Ausdruck noch fremd vorkommt, dann ist das nicht schlimm. Wir werden im Kapitel 2 ausführlich auf lineare Regressionsmodelle eingehen. Im Moment müssen Sie nur wissen, dass ein parametrisches Modell wie oben mit einer mathematischen Funktion beschrieben werden kann und dass diese Funktion durch lernbare Parameter (hier \\(w_0\\) und \\(w_1\\)) charakterisiert wird.\nNicht-parametrische Modelle wiederum sind Modelle, welche nicht (oder zumindest nicht explizit) durch Parameter charakterisiert sind. Am besten schauen wir uns kurz ein einfaches nicht-parametrisches Modell an, nämlich das K-Nearest-Neighbors (KNN) Modell. Ein KNN Modell verwendet für die Vorhersage einer neuen Beobachtung die \\(K\\) nächsten bzw. ähnlichsten (Nachbars-)Beobachtungen. Doch wie werden die Vorhersagen gemacht?\n\nKlassifikationsproblem: die häufigste Outputkategorie unter den \\(K\\) Nachbarn ist die Vorhersage für den neuen Datenpunkt.\nRegressionsproblem: der Mittelwert der Outputwerte \\(y_i\\) unter den \\(K\\) Nachbarn ist die Vorhersage für den neuen Datenpunkt.\n\nDas KNN Modell ist ein sehr einfaches ML Modell, welches in der Praxis allerdings nicht allzu häufig angewendet wird. Warum nicht? Weil es am sogenannten Fluch der Dimensionalität (engl. Curse of Dimensionality) leidet. Doch was bedeutet das? Je mehr Input-Variablen wir haben, desto weiter entfernt sind Datenpunkte voneinander (das ist etwas, das man sich nur schwer vorstellen kann, aber Sie können es mir für den Moment einfach mal glauben). Das KNN beruht auf der Grundidee, dass wir \\(K\\) nahe, ähnliche Beobachtungen für die Vorhersage verwenden. Wenn diese \\(K\\) nahen Beobachtungen im hochdimensionalen Raum (= viele Input-Variablen) nicht mehr nahe sind, dann funktioniert auch das Modell nicht mehr gut. Wir werden uns in Kapitel 3 ausführlicher mit dem KNN Modell und dem Fluch der Dimensionalität befassen.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einführung</span>"
    ]
  },
  {
    "objectID": "01_intro.html#perceptron-und-erste-mathematische-konzepte",
    "href": "01_intro.html#perceptron-und-erste-mathematische-konzepte",
    "title": "1  Einführung",
    "section": "1.7 Perceptron und erste mathematische Konzepte",
    "text": "1.7 Perceptron und erste mathematische Konzepte\nWir versuchen nun hier die Anfänge des MLs auch aus technischer Sicht zu verstehen und zwar schauen wir uns die Funktionsweise von Frank Rosenblatt’s Perceptron an. Der Einfachheit halber schauen wir uns ein Beispiel mit nur zwei Input-Variablen \\(x_{i1}\\) und \\(x_{i2}\\) an. Ausserdem befinden wir uns im binären Klassifikationsfall mit zwei möglichen Kategorien, die als \\(y_i \\in \\{-1, 1\\}\\) kodiert sind (wir werden später sehen, warum wir hier nicht eine 0/1 Kodierung wählen). Dieser Abschnitt ist inspiriert durch (Ananthaswamy 2024, Kap. 2).\n\n1.7.1 Datenpunkte als Vektoren\nJeder Datenpunkt (bzw. Beobachtung) \\(\\mathbf{x}_i\\) kann als Vektor im Koordinatensystem dargestellt werden. Da wir uns hier auf zwei Input-Variablen beschränken, kann dieses Koordinatensystem einfach visualisiert werden:\n\n\n\n\n\nKoordinatensystem mit zwei Dimensionen und einem Datenpunkt (-4.1, 3.5).\n\n\n\n\nDer Datenpunkt \\(\\mathbf{x}_i = \\begin{pmatrix} -4.1 & 3.5 \\end{pmatrix}'\\)7 ist aus geometrischer Sicht ein Vektor in diesem zweidimensionalen Raum.\n\n\n\n\n\n\nHinweisDefinition eines Vektors\n\n\n\nEin Vektor ist definiert durch zwei Dinge: (i) seine Richtung im Koordinatensystem und (ii) seine Länge. Ein Vektor muss nicht zwingend am Ursprung des Koordinatensystems (0, 0) beginnen. Das heisst, zwei Vektoren mit identischer Richtung und Länge, aber an unterschiedlichen Orten im Koordinatensystem, gelten als identisch.\nDie Richtung des Vektors ist durch seine Koordinaten bereits definiert.\nDie Länge eines Vektors \\(\\mathbf{x}_i = \\begin{pmatrix} x_{i1} & x_{i2} \\end{pmatrix}'\\) berechnet sich wie folgt:\n\\[\n\\| \\mathbf{x}_i \\| = \\sqrt{x_{i1}^2 + x_{i2}^2}\n\\]\n\n\n\nFrage\nWelche Länge hat unser Vektor \\(\\mathbf{x}_i = \\begin{pmatrix} -4.1 & 3.5 \\end{pmatrix}'\\) im Beispiel oben?\n\n\n\n\n\n\nTippLösung\n\n\n\n\n\n\\[\n\\| \\mathbf{x}_i \\| = \\sqrt{{-4.1}^2 + {3.5}^2} = 5.39\n\\]\n\n\n\nNun kommen wir bereits zu einem der aus meiner Sicht wichtigsten mathematischen Operationen im Machine Learning: das Skalarprodukt. Wenn Sie das Skalarprodukt gut verstehen, dann werden viele der Konzepte später massiv einfacher zu verstehen sein.\n\n\n\n\n\n\nVorsichtSkalarprodukt\n\n\n\n\n\nDas Skalarprodukt zwischen zwei Vektoren kann aus zwei Perspektiven betrachtet werden: einer geometrischen und einer algebraischen. Das Resultat ist aber in beiden Fällen dasselbe, nämlich ein Skalar (also irgendeine reelle Zahl).\nIn der geometrischen Perspektive entspricht das Skalarprodukt zwischen zwei Vektoren \\(\\mathbf{a}\\) und \\(\\mathbf{b}\\) dem Produkt der Länge von \\(\\mathbf{a}\\) sowie der Länge der orthogonalen Projektion von \\(\\mathbf{b}\\) auf \\(\\mathbf{a}\\). Wir können das selbstverständlich als Formel aufschreiben. Weil wir das ganze aus einer geometrischen Perspektive betrachten, verwenden wir die geomtrische Schreibweise von Vektoren (mit Pfeilen oberhalb der Variablennamen):\n\\[\n\\vec{a} \\cdot \\vec{b} = \\| \\vec{a} \\| \\; \\| \\vec{b} \\| \\cos(\\varphi)\n\\] Wir multiplizieren also die Länge von \\(\\mathbf{a}\\) (also \\(\\| \\vec{a} \\|\\)) mit der Länge der orthogonalen Projektion von \\(\\mathbf{b}\\) auf \\(\\mathbf{a}\\) (definiert durch \\(\\| \\vec{b} \\| \\cos(\\varphi)\\)). Der Winkel \\(\\varphi\\) ist der Winkel zwischen den beiden Vektoren.\nFolgendes Beispiel hilft das ganze zu veranschaulichen. Die Projektion des roten Vektors \\(\\vec{b}\\) auf den blauen Vektor \\(\\vec{a}\\) ist dargestellt durch die gestrichelte Linie, die vom roten Vektor senkrecht auf den blauen trifft. Der Winkel zwischen den beiden Vektoren beträgt 40.6 Grad.\n\n\n\n\n\n\nAbbildung 1.2: Skalarprodukt aus geometrischer Sicht.\n\n\n\nMit obiger Formel können wir nun problemlos das Skalarprodukt zwischen den beiden Vektoren berechnen:\n\\[\n\\vec{a} \\cdot \\vec{b} = \\sqrt{{3}^2 + {1}^2} \\cdot  \\sqrt{{3}^2 + {5}^2} \\cdot \\cos(40.6) = \\sqrt{10} \\cdot \\sqrt{34} \\cdot 0.76 = 14\n\\]\nDoch was genau misst eigentlich das Skalarprodukt? Es misst, wie stark ein Vektor in die Richtung des anderen Vektors zeigt.\nEs gibt weitere wichtige Eigenschaften des Skalarprodukts:\n\nZeigen die beiden Vektoren in die gleiche Richtung ist der Winkel zwischen den Vektoren 0 Grad und \\(\\cos(0)=1\\). In diesem Fall reduziert sich das Skalarprodukt auf das Produkt der beiden Längen.\nStehen die Vektoren in einem rechten Winkel zueinander, dann ist \\(\\cos(90)=0\\) und das Skalarprodukt wird immer 0 sein. Diese Eigenschaft müssen Sie sich unbedingt merken, denn sie taucht überall im ML immer wieder auf!\nDas Skalarprodukt ist symmetrisch. Es spiel also keine Rolle, ob wir das Skalarprodukt zwischen \\(\\vec{a}\\) und \\(\\vec{b}\\) oder das Skalarprodukt zwischen \\(\\vec{b}\\) und \\(\\vec{a}\\) rechnen. Das Resultat wird dasselbe sein.\n\nAus der algebraischen Perspektive ist die Berechnung zum Glück noch einfacher. Wir berechnen das Skalarprodukt hier einfach als Summe über die elementweisen Multiplikationen der Koordinaten:\n\\[\n\\vec{a} \\cdot \\vec{b} = a_1\\,b_1 + a_2\\,b_2 = 3 \\cdot 3 + 1 \\cdot 5 = 14\n\\]\nIm Machine Learning ist es üblich, das Skalarprodukt als Produkt des transponierten Vektors \\(\\mathbf{a}\\) und des Vektors \\(\\mathbf{b}\\) zu schreiben, also:\n\\[\n\\mathbf{a}'\\, \\mathbf{b} = \\begin{pmatrix} 3 & 1 \\end{pmatrix} \\begin{pmatrix} 3 \\\\ 5 \\end{pmatrix} = 3 \\cdot 3 + 1 \\cdot 5 = 14\n\\]\n\n\n\nNun sind wir bereit, uns das Perceptron erst aus mathematischer und dann aus geometrischer Sicht anzuschauen.\n\n\n\n1.7.2 Das Perceptron (mathematische Sicht)\nDas Perceptron ist ein parametrisches Modell und wird in unserem Beispiel mit zwei Input-Variablen durch drei Parameter (oder Gewichte) \\(w_0\\), \\(w_1\\) und \\(w_2\\) charakterisiert.\nIn einem ersten Schritt werden diese drei Gewichte verwendet, um eine gewichtete Summe der Input-Variablenwerte zu rechnen:\n\\[\nw_0 + w_1 \\cdot x_{i1} + w_2 \\cdot x_{i2}\n\\]\nVielleicht erkennen Sie bereits, dass diese gewichtete Summe dem Skalarprodukt ähnelt. Mit einem kleinen Trick können wir diese gewichtete Summe tatsächlich als Skalarprodukt ausdrücken, nämlich indem wir dem Input-Datenvektor \\(\\mathbf{x}_i\\) noch eine 1 voranhängen:\n\\[\n\\mathbf{w}'\\,\\mathbf{x}_i = \\begin{pmatrix} w_0 & w_1 & w_2 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ x_{i1} \\\\ x_{i2} \\end{pmatrix} = w_0 \\cdot 1 + w_1 \\cdot x_{i1} + w_2 \\cdot x_{i2}\n\\]\nIn einem zweiten Schritt wird der Wert der gewichteten Summe verglichen mit dem Schwellenwert 0, um zu entscheiden, ob der Output \\(\\hat{y}_i\\) des Perceptrons -1 oder +1 ist. Man nennt dies eine sogenannte Step-Funktion, die folgendermassen geschrieben werden kann:\n\\[\n\\hat{y}_i = \\begin{cases}\n            -1, & \\mathbf{w}'\\,\\mathbf{x}_i &lt; 0\\\\\n      +1, & \\mathbf{w}'\\,\\mathbf{x}_i \\geq 0\n        \\end{cases}\n\\]\nWir können diese zwei Schritte auch grafisch darstellen. Das Summenzeichen im grünen Kreis in Abbildung 1.3 soll den ersten Schritt, die Berechnung der gewichteten Summe der Input-Variablenwerte, darstellen. Das Zeichen rechts davon stellt die Step-Funktion dar, etwas, das wir später als sogenannte Aktivierung verallgemeinern werden.\n\n\n\n\n\n\nAbbildung 1.3: Ein Perceptron mit einer Einheit.\n\n\n\n\n\n1.7.3 Das Perceptron (geometrische Sicht)\nAus geometrischer Sicht kann man sich das Perceptron mit zwei Input-Variablen als Gerade im Koordinatensystem vorstellen, welche die Beobachtungen der einen Kategorie von den Beobachtungen der anderen Kategorie trennt.8\nFür jeden Datenpunkt, der genau auf dieser trennenden Geraden liegt, muss gelten, dass \\(\\mathbf{w}'\\,\\mathbf{x}_i = 0\\). Aus der Einführung zum Skalarprodukt wissen wir, dass wenn das Skalarprodukt 0 ist die Vektoren in einem rechten Winkel zueinander stehen, oder in anderen Worten, orthogonal sind.\nWir sehen in untenstehender Abbildung, dass dies tatsächlich so ist. Die Gerade (in Grün) trennt die 5 Datenpunkte perfekt auf in die zwei Kategorien (blaue Kreise und rote Dreiecke). Der Gewichtsvektor (definiert durch die Gewichte \\(w_1\\) und \\(w_2\\)) steht in einem rechten Winkel zur Geraden. Der Gewichtsvektor charakterisiert also indirekt die Gerade (oder allgemeiner: die Hyperebene), weil diese Orthogonalität immer gegeben ist.\nDoch was ist der Zweck des Gewichts \\(w_0\\)? Dieser Parameter stellt sicher, dass die Gerade nicht durch den Nullpunkt (0, 0) gehen muss. \\(w_0\\) erlaubt dem Perceptron also mehr Flexibilität. Man spricht bei \\(w_0\\) in der Fachsprache häufig vom Bias Term. Sie sehen anhand der Grafik, dass eine Gerade, die durch den Nullpunkt gehen muss, die zwei Kategorien nicht voneinander trennen könnte.\n\n\n\n\n\n\n\n\n\n\nFrage\nWie können wir aus der Gleichung \\(w_0 + w_1 \\cdot x_{i1} + w_2 \\cdot x_{i2} = 0\\) die Steigung der Geraden und den Punkt, wo die Gerade die y-Achse schneidet, berechnen?\n\n\n\n\n\n\nTippLösung\n\n\n\n\n\nWir können die Gleichung nach den Regeln der Algebra umformen, so dass wir auf der linken Seite der Gleichung nur noch \\(x_2\\) haben:\n\\[\n\\begin{align}\nw_0 + w_1 \\cdot x_{i1} + w_2 \\cdot x_{i2} &= 0 \\\\\nw_2 \\cdot x_{i2} &= - w_0 - w_1 \\cdot x_{i1} \\\\\nx_{i2} &= - \\frac{w_0}{w_2} - \\frac{w_1}{w_2} \\cdot x_{i1}\n\\end{align}\n\\]\nDaran erkennen wir, dass die Gerade eine Steigung von \\(- \\frac{w_1}{w_2}\\) und eine Konstante von \\(- \\frac{w_0}{w_2}\\) hat. In unserem Beispiel wäre die Steigung -0.49 und die Konstante 1.14.\n\n\n\n\n\n\n1.7.4 Wie lernt das Perceptron?\nIm vorherigen Abschnitt waren die optimalen Gewichte gegeben, doch das eigentlich Erstaunliche am Perceptron ist der von Rosenblatt vorgeschlagene Perceptron Learning Algorithm, welcher nach einer gewissen Anzahl Iterationen Werte für die Gewichte findet, so dass die beiden Kategorien perfekt voneinander getrennt werden.\nDoch wie funktioniert dieser Algorithmus? Er ist enorm simpel und verfährt in drei Schritten:\n\nDie Gewichte werden mit 0 initialisiert also \\(\\mathbf{w}=0\\).\nNun iterieren wir. Jede Iteration geht durch die Datenpunkte und berechnet \\(y_i\\,\\mathbf{w}'\\,\\mathbf{x}_i\\). Falls \\(y_i\\,\\mathbf{w}'\\,\\mathbf{x}_i \\leq 0\\), werden die Gewichte angepasst und zwar wie folgt: \\[\n\\mathbf{w} := \\mathbf{w} + y_i\\,\\mathbf{x}_i\n\\]\nWenn in Schritt 2 der Gewichtsvektor für keinen Datenpunkt angepasst werden musste, dann sind wir fertig und beenden die Iteration.\n\nDoch wie funktioniert Schritt 2? Wenn die Berechnung \\(\\mathbf{w}'\\,\\mathbf{x}_i\\) einen negativen Wert ergibt und \\(y_i = -1\\), dann sind die Gewichte für den Datenpunkt \\(i\\) gut und müssen nicht aktualisiert werden. Dasselbe gilt, wenn sowohl \\(\\mathbf{w}'\\,\\mathbf{x}_i\\) und \\(y_i\\) positiv sind.\nWenn \\(\\mathbf{w}'\\,\\mathbf{x}_i\\) und \\(y_i\\) jedoch unterschiedliche Vorzeichen haben, dann bedeutet dies, dass eine falsche Klassifikation vorliegt. Der Datenpunkt liegt auf der falschen Seite der Geraden. Im Panel oben links in untenstehender Abbildung ist das für das rote Dreieck, das oberhalb der Geraden liegt der Fall. In der Iteration 2 machen wir für diesen Datenpunkt folgende Anpassung:\n\\[\n\\mathbf{w} := \\begin{pmatrix} 0 \\\\ 2.1 \\\\ -2.5 \\end{pmatrix} + 1\\,\\begin{pmatrix} 1 \\\\ -2 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 0.1 \\\\ -1.5 \\end{pmatrix}\n\\]\nIm Panel oben rechts (Resultat nach Iteration 2) sehen wir, dass mit dieser Operation die Gerade so verschoben wird, dass der falsch klassifizierte Datenpunkt etwas näher an der korrekten Seite der Gerade liegt. Der Algorithmus lernt also von Fehlern und tastet sich iterativ an das Optimum heran - eine Idee, die wir in späteren Kapiteln häufig antreffen werden.\nIm Panel rechts unten sehen wir, dass der Algorithmus nach 10 Iterationen die Datenpunkte bereits korrekt klassifiziert. Wow!\n\n\n\n\n\n\n\n\n\n\n\n1.7.5 Das XOR Problem\nAls das Perceptron und der Lernalgorithmus in den 50er und 60er Jahre bekannt wurde, herrschte eine regelrechte Euphorie. Man hatte ein Modell und einen Lernalgorithmus gefunden, die aus Datenpunkten korrekte Klassifizierungsregeln selbständig lernen konnten, und zwar nicht nur in zwei Dimensionen, wo man das korrekte Resultat von Auge sieht, sondern auch in hochdimensionalen Räumen, wo die Aufgabe viel schwieriger ist.\nDoch bald legte sich die Euphorie und der erste “KI-Winter”9 trat ein: das Interesse an KI verschwand und auch der Wille weitere Forschung zu finanzieren war massiv kleiner. Doch warum? Weil man bald merkte, dass das Perceptron nur für linear separierbare Probleme funktioniert. Auf unser Beispiel übertragen heisst das, nur wenn wir die Datenpunkte mit einer Geraden in die zwei Kategorien aufteilen können.\nUm das Problem zu veranschaulichen, wird oft auf das Exclusive OR (XOR) Problem zurück gegriffen. Im XOR Problem haben wir zwei Input-Variablen \\(x_{i1}\\) und \\(x_{i2}\\), welche beide nur die Werte 0 oder 1 annehmen können. Der Output für eine Beobachtung folgt einer exklusiven ODER Logik, welche von den Input-Variablenwerte abhängt. Folgende vier Fälle sind möglich:\n\nFalls \\(x_{i1}=0\\) und \\(x_{i2}=0\\), dann ist \\(y_i=-1\\).\nFalls \\(x_{i1}=1\\) und \\(x_{i2}=1\\), dann ist \\(y_i=-1\\).\nFalls \\(x_{i1}=1\\) und \\(x_{i2}=0\\), dann ist \\(y_i=+1\\).\nFalls \\(x_{i1}=0\\) und \\(x_{i2}=1\\), dann ist \\(y_i=+1\\).\n\nEine Beobachtung \\(i\\) hat also nur dann einen Outputwert von +1, wenn eine der Input-Variablen den Wert 1 annimmt. In der nicht-exklusiven ODER Logik würden auch \\(x_{i1}=1\\) und \\(x_{i2}=1\\) zu einem Outputwert von +1 führen.\nGrafisch kann das XOR Problem durch folgende vier Datenpunkte visualisiert werden:\n\n\n\n\n\n\n\n\n\nIch hoffe Sie sehen, dass hier keine Gerade gezeichnet werden kann, welche die zwei Kategorien korrekt voneinander trennt. Ironischerweise wäre die Lösung für dieses Problem nicht schwierig gewesen: man musste einfach mindestens zwei Perceptron-Einheiten nacheinander anordnen und das Problem wäre lösbar gewesen. Aber um darauf zu kommen und die mathematischen Grundlagen zu schaffen, brauchte es erst ein paar Jahrzehnte mehr Forschung von Leuten, die sich von der Enttäuschung nicht aufhalten liessen. Wir werden im zweiten Teil dieses Buchs auf das Perceptron und das XOR Problem zurückkommen.\n\n\n\n\n\n\n\n\n\nAnanthaswamy, Anil. 2024. Why Machines Learn: The Elegant Math Behind Modern AI. Dutton.\n\n\nGéron, Aurélien. 2022. Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems. 3. Aufl. O’Reilly.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einführung</span>"
    ]
  },
  {
    "objectID": "01_intro.html#footnotes",
    "href": "01_intro.html#footnotes",
    "title": "1  Einführung",
    "section": "",
    "text": "https://home.dartmouth.edu/about/artificial-intelligence-ai-coined-dartmouth↩︎\nhttps://en.wikipedia.org/wiki/Frank_Rosenblatt↩︎\nhttps://www.image-net.org/↩︎\nhttps://de.wikipedia.org/wiki/Anscombe-Quartett↩︎\nhttps://deepmind.google/technologies/alphago/↩︎\nIn Statistikvorlesungen werden die beiden Parameter oft eher mit \\(b_0\\) und \\(b_1\\) oder mit \\(\\beta_0\\) und \\(\\beta_1\\) bezeichnet. Im Machine Learning nennt man Parameter oft Gewichte (engl. Weights), weshalb die Parameter typischerweise mit \\(w\\) bezeichnet werden.↩︎\nDa ein Spaltenvektor im Text nicht gut geschrieben werden kann, schreiben wir \\(\\mathbf{x}_i\\) als transponierten Zeilenvektor, was wiederum dem Spaltenvektor entspricht↩︎\nIn höherdimensionalen Räumen sind es anstelle von Geraden sogenannte Hyperebenen.↩︎\nhttps://en.wikipedia.org/wiki/AI_winter↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einführung</span>"
    ]
  },
  {
    "objectID": "classical.html",
    "href": "classical.html",
    "title": "Klassisches Machine Learning",
    "section": "",
    "text": "Nachdem wir in 1  Einführung in das Thema Machine Learning eingestiegen sind, befassen wir uns nun in einem ersten Teil des Buchs mit den klassischen Methoden des Supervised Learnings.\nEs ist jedoch wichtig zu erwähnen, dass die folgenden Kapitel lediglich einen ersten Einblick in dieses Thema geben. Es gibt zahlreiche weitere Themen, Modelle und Methoden aus dem Supervised Learnings. Ausserdem ignorieren wir das Thema Unsupervised Learning fast komplett.\nNichtsdestotrotz haben Sie nach Bearbeitung der folgenden Kapitel eine sehr gute Basis, um tiefer in das Thema einzusteigen. Sie sollten nach dem Lesen ausserdem auch die Notation und die wichtigsten mathematischen Grundlagen in ihrem Köcher haben, damit Sie weiterführende Bücher und Materialien gut verstehen sollten.",
    "crumbs": [
      "Klassisches Machine Learning"
    ]
  },
  {
    "objectID": "02_linreg.html",
    "href": "02_linreg.html",
    "title": "2  Lineare Regression",
    "section": "",
    "text": "2.1 ML-Modelle im Allgemeinen\nIn diesem Kapitel werden wir uns eingehend mit dem einfachsten Modell für das Regressionsproblem auseinander setzen, nämlich dem linearen Regressionsmodell. Liegt ein Regressionsproblem vor, dann macht es in der Praxis fast immer Sinn mit diesem Modell zu starten und dann die Komplexität nach Bedarf zu erhöhen.\nWie bereits in Kapitel 1 gesehen, geht es beim Regressionsproblem darum, eine stetige Variable \\(y_i \\in \\mathbb{R}\\) möglichst optimal vorherzusagen. Dazu verwenden wir eine oder mehrere Input-Variablen, welche wir kompakt als Vektor \\(\\mathbf{x}_i\\) schreiben.\nDas Problem ist nur sinnvoll lösbar, falls es tatsächlich einen Zusammenhang zwischen den Input-Variablen \\(\\mathbf{x}_i\\) und dem Output \\(y_i\\) gibt, wenn wir also aus \\(\\mathbf{x}_i\\) etwas über \\(y_i\\) lernen können. Wir nehmen ganz allgemein an, dass der Zusammenhang zwischen dem Output \\(y_i\\) und den Input-Variablen \\(\\mathbf{x}_i\\) mathematisch wie folgt ausgedrückt werden kann (James u. a. 2021, Kap. 2):\n\\[\ny_i = f(\\mathbf{x}_i) + \\epsilon\n\\]\nDer Output \\(y_i\\) ergibt sich also aus der Addition des systematischen Teils \\(f(\\mathbf{x}_i)\\) sowie des Fehlerterms \\(\\epsilon\\).",
    "crumbs": [
      "Klassisches Machine Learning",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Lineare Regression</span>"
    ]
  },
  {
    "objectID": "02_linreg.html#ml-modelle-im-allgemeinen",
    "href": "02_linreg.html#ml-modelle-im-allgemeinen",
    "title": "2  Lineare Regression",
    "section": "",
    "text": "Die Funktion \\(f(\\mathbf{x}_i)\\) bezeichnet die systematische Information, die wir aus \\(\\mathbf{x}_i\\) im Hinblick auf \\(y_i\\) lernen können. Oder in anderen Worten: \\(f\\) mappt die Input-Werte \\(\\mathbf{x}_i\\) auf die Output-Werte \\(y_i\\).\n\\(\\epsilon\\) ist ein Fehlerterm, der die Differenz zwischen \\(y_i\\) und \\(f(\\mathbf{x}_i)\\) abbildet,1 also den nicht-lernbaren (unsystematischen) Teil. Der Fehlerterm beinhaltet einerseits den Effekt von Variablen, die uns nicht zur Verfügung stehen, aber einen Einfluss auf den Output \\(y_i\\) haben und andererseits nicht-messbare Variation in \\(y_i\\), oft auch einfach Noise genannt. Grob gesagt: alles nicht-messbare. Auch wichtig zu sehen: der Fehler ist additiv, wir addieren ihn zum lernbaren Teil hinzu.\n\n\n\n\n\n\n\n\nHinweisZiel des Machine Learnings\n\n\n\nZiel des Machine Learnings ist es, eine Funktion \\(\\hat{f}(\\mathbf{x}_i)\\) zu trainieren (schätzen), die der wahren aber unbekannten Funktion \\(f(\\mathbf{x}_i)\\) so nahe wie möglich kommt. Im (unrealistischen) Idealfall ist unser trainiertes Modell gleich der wahren Funktion, also \\(\\hat{f}(\\mathbf{x}_i) = f(\\mathbf{x}_i)\\) und wir haben die systematische Information perfekt gelernt.\nSobald wir \\(\\hat{f}(\\mathbf{x}_i)\\) trainiert haben, können wir damit Vorhersagen machen, denn die Vorhersage für eine neue Beobachtung \\(\\mathbf{x}_0\\) ist nichts anderes als der Wert der trainierten Funktion an diesem Punkt, also \\(\\hat{y}_0 = \\hat{f}(\\mathbf{x}_0)\\).\nJedes ML-Modell, das wir uns in diesem Buch anschauen werden, kann als eine mathematische Funktion \\(\\hat{f}(\\mathbf{x}_i)\\) der Input-Variablen \\(\\mathbf{x}_i\\) aufgeschrieben werden.",
    "crumbs": [
      "Klassisches Machine Learning",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Lineare Regression</span>"
    ]
  },
  {
    "objectID": "02_linreg.html#das-modell-ausgeschrieben",
    "href": "02_linreg.html#das-modell-ausgeschrieben",
    "title": "2  Lineare Regression",
    "section": "2.2 Das Modell (ausgeschrieben)",
    "text": "2.2 Das Modell (ausgeschrieben)\nNun wollen wir uns konkret mit dem linearen Regressionsmodell befassen. Das bedeutet nun nichts anderes, als dass wir die allgemein geschriebene Funktion \\(f(\\mathbf{x}_i)\\) durch eine konkrete mathematische Funktion ersetzen. Im Machine Learning ist das der erste wichtige Schritt, nämlich die Modellwahl (engl. Model Selection). Das Modell kann wie folgt geschrieben werden:\n\\[\nf(\\mathbf{x}_i) = w_0 + w_1 \\cdot x_{i1} + w_2 \\cdot x_{i2} + \\ldots + w_p \\cdot x_{ip}\n\\] Wir verzichten hier bewusst darauf, den Hut für \\(f\\) zu schreiben, da es sich lediglich um eine allgemein gültige Funktion handelt und noch nichts geschätzt bzw. trainiert wurde. Dieses Modell bzw. diese Funktion hat sogenannte Parameter, die es zu schätzen gilt. Es handelt sich also auch hier um ein parametrisches Modell. Hier sind dies die Parameter \\(w_0,\\; w_1,\\; \\ldots,\\; w_p\\). Wegen der Konstante \\(w_0\\) haben wir immer einen Parameter mehr als es Input-Variablen hat, also \\(p+1\\) Parameter.\nDiese Parameter sind die Schlüsselzutat in einem ML-Modell. Wir wollen sie optimieren, so dass die trainierte Funktion \\(\\hat{f}(\\mathbf{x}_i)\\) der wahren Funktion \\(f(\\mathbf{x}_i)\\) möglichst nahe kommt und die beobachteten Daten möglichst gut beschreibt.\nWir schauen uns in diesem Kapitel ein ganz einfaches Beispiel mit nur einer Input-Variable \\(x_i\\) an, so dass der Zusammenhang zwischen dem Output \\(y_i\\) und dem Input \\(x_i\\) in 2D dargestellt werden kann. In diesem Zusammenhang spricht man vom einfachen linearen Regressionsmodell. Ausserdem haben wir nur vier Beobachtungen, welche in folgender Abbildung in einem Streudiagramm dargestellt werden:\n\n\n\n\n\nEinfaches Regressionsbeispiel. Die vier Beobachtungen werden in einem Streudiagramm dargestellt. Auf der x-Achse ist der Wert der Input-Variable und auf der y-Achse der Wert der Output-Variable ablesbar.\n\n\n\n\nObwohl obige Abbildung ähnlich aussieht wie die Abbildungen zum Perceptron, gibt es hier einen bedeutenden Unterschied. Auf der y-Achse des Streudiagramm wird der Outputwert der Beobachtungen dargestellt, während auf der x-Achse der Input-Wert angezeigt wird. Es wird nun darum gehen, eine Gerade zu finden, welche die vier Beobachtungen bestmöglich repräsentiert.",
    "crumbs": [
      "Klassisches Machine Learning",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Lineare Regression</span>"
    ]
  },
  {
    "objectID": "02_linreg.html#das-modell-kompakt",
    "href": "02_linreg.html#das-modell-kompakt",
    "title": "2  Lineare Regression",
    "section": "2.3 Das Modell (kompakt)",
    "text": "2.3 Das Modell (kompakt)\nSie haben oben gesehen, dass es ziemlich umständlich sein kann, das lineare Regressionsmodell aufzuschreiben, insbesondere wenn wir viele Input-Variablen haben. Mithilfe von Vektoren und Matrizen können wir das Modell viel kompakter aufschreiben.\nWir haben in Kapitel 1 bereits gesehen, dass die Input-Variablen für eine Beobachtung \\(i\\) als Spaltenvektor geschrieben werden können. Wir modifizieren diesen Spaltenvektor in einem ersten Schritt, indem wir an erster Stelle eine 1 einfügen,2 also:\n\\[\\mathbf{x}_i=\\begin{pmatrix} 1\\\\ x_{i1} \\\\ x_{i2} \\\\ \\vdots \\\\ x_{ip} \\end{pmatrix}\\]\nNun stecken wir die Parameter des Modells ebenfalls in einen Spaltenvektor:\n\\[\\mathbf{w}=\\begin{pmatrix} w_0 \\\\ w_1 \\\\ w_2 \\\\ \\vdots \\\\ w_p \\end{pmatrix}\\]\nWie bereits für das Perceptron gesehen, können wir das lineare Regressionsmodell (für die Beobachtung \\(i\\)) als Skalarprodukt dieser beiden Vektoren aufschreiben:\n\\[\\begin{align}\nf(\\mathbf{x}_i) &= \\mathbf{w}' \\mathbf{x_i}\\\\\n&= \\begin{pmatrix} w_0 & w_1 & w_2 & \\dots & w_p \\end{pmatrix} \\begin{pmatrix} 1\\\\ x_{i1} \\\\ x_{i2} \\\\ \\vdots \\\\ x_{ip} \\end{pmatrix}\\\\\n&= w_0 \\cdot 1 + w_1 \\cdot x_{i1} + w_2 \\cdot x_{i2} + \\dots + w_p \\cdot x_{ip}\n\\end{align}\\]\n\nFrage\nDoch Moment mal, das lineare Regressionsmodell sieht ja genau gleich wie ein Perceptron aus. Wie unterscheiden sich die beiden Modelle im Hinblick darauf, was mit \\(\\mathbf{w}' \\mathbf{x_i}\\) gemacht wird?\n\n\n\n\n\n\nTippLösung\n\n\n\n\n\nGrundsätzlich gilt: das Perceptron ist ein Klassifikationsmodell, während das lineare Regressionsmodell zur Lösung von Regressionsproblemen dient.\nBeim Perceptron haben wir \\(\\mathbf{w}' \\mathbf{x_i}\\) verglichen mit dem Schwellenwert 0, um zu entscheiden, ob wir eine Beobachtung der Kategorie -1 oder +1 zuweisen.\nHier, beim linearen Regressionsmodell, soll \\(\\mathbf{w}' \\mathbf{x_i}\\) den stetigen (numerischen) Outputwert \\(y_i\\) möglichst gut abbilden.\n\n\n\nDie Form \\(\\mathbf{w}' \\mathbf{x_i}\\) ist schon ziemlich kompakt, aber es geht noch besser. Wir können nämlich das Modell gleich für alle \\(n\\) Beobachtungen (und nicht nur für die \\(i\\)-te Beobachtung) aufschreiben. Dazu müssen wir die Input-Variablen für jede Beobachtung \\(i\\) in einer Matrix anordnen:\n\\[\n\\mathbf{X} = \\begin{pmatrix}\n1 & x_{11} & x_{12} & \\cdots & x_{1p}\\\\\n1 & x_{21} & x_{22} & \\cdots & x_{2p}\\\\\n\\vdots & \\cdots & \\cdots & \\ddots & \\vdots\\\\\n1 & x_{n1} & x_{n2} & \\cdots & x_{np}\\\\\n\\end{pmatrix}\n\\]\nDie Matrix \\(\\mathbf{X}\\) wird typischerweise Design Matrix genannt. Die erste Zeile enthält die Input-Variablen für die erste Beobachtung, die zweite Zeile die Input-Variablen für die zweite Beobachtung, usw. Nun können wir das Modell mithilfe einer Multiplikation zwischen der Design Matrix \\(\\mathbf{X}\\) und dem Spaltenvektor \\(\\mathbf{w}\\) in einem Schritt für alle Beobachtungen aufschreiben:\n\\[\\begin{align}\nf(\\mathbf{X}) &= \\mathbf{X}\\mathbf{w}\\\\\n&= \\begin{pmatrix}\n1 & x_{11} & x_{12} & \\cdots & x_{1p}\\\\\n1 & x_{21} & x_{22} & \\cdots & x_{2p}\\\\\n\\vdots & \\cdots & \\cdots & \\ddots & \\vdots\\\\\n1 & x_{n1} & x_{n2} & \\cdots & x_{np}\\\\\n\\end{pmatrix}\\begin{pmatrix} w_0 \\\\ w_1 \\\\ w_2 \\\\ \\dots \\\\ w_p \\end{pmatrix}\\\\\n&= \\begin{pmatrix}\nw_0 \\cdot 1 + w_1 \\cdot x_{11} + w_2 \\cdot x_{12} + \\dots + w_p \\cdot x_{1p} \\\\\nw_0 \\cdot 1 + w_1 \\cdot x_{21} + w_2 \\cdot x_{22} + \\dots + w_p \\cdot x_{2p} \\\\\n\\cdots \\\\\nw_0 \\cdot 1 + w_1 \\cdot x_{n1} + w_2 \\cdot x_{n2} + \\dots + w_p \\cdot x_{np}\\end{pmatrix}\n\\end{align}\\]\nÜberprüfen wir doch noch kurz die Dimensionen von obigem Matrix-Vektor Produkt. Die Matrix \\(\\mathbf{X}\\) hat \\(n\\) Zeilen und \\(p+1\\) Spalten und darum eine Dimensionalität von \\(n \\times (p+1)\\). Der Spaltenvektor \\(\\mathbf{w}\\) hat Dimensionalität \\((p+1) \\times 1\\). Das Matrix-Vektor Produkt hat dementsprechend eine Dimensionalität von \\(n \\times 1\\), genau was wir erwarten würden, nämlich einen (Spalten-)Vektor mit den Vorhersagen für alle \\(n\\) Beobachtungen.\n\n\n\n\n\n\nVorsichtMatrixprodukt\n\n\n\n\n\nWenn das Produkt zweier Matrizen \\(\\mathbf{A}\\) und \\(\\mathbf{B}\\) gerechnet werden soll, dann gilt es immer zuerst die Dimensionen der beiden Matrizen zu prüfen. Warum? Die Multiplikation \\(\\mathbf{A}\\mathbf{B}\\) funktioniert nämlich nur dann, wenn die Anzahl Spalten von \\(\\mathbf{A}\\) gleich der Anzahl Zeilen von \\(\\mathbf{B}\\) ist.\nNehmen wir an, dass \\(\\mathbf{A}\\) eine Dimensionalität von \\(m \\times n\\) hat (\\(\\mathbf{A}\\) hat also \\(m\\) Zeilen und \\(n\\) Spalten). Die Matrix \\(\\mathbf{B}\\) hat eine Dimensionalität von \\(n \\times p\\).\nIn diesem Fall ist obige Bedingung schon mal erfüllt, denn die Anzahl Spalten von \\(\\mathbf{A}\\) (also \\(n\\)) ist gleich der Anzahl Zeilen von \\(\\mathbf{B}\\).\nWeiter gilt, dass die resultierenden Matrix \\(\\mathbf{C}=\\mathbf{A}\\mathbf{B}\\) eine Dimensionalität von \\(m \\times p\\) hat.\nDoch wie berechnet man die Element der resultierenden Matrix \\(\\mathbf{C}\\)?\nDas erste Element links oben in der Matrix (man kann es als \\(\\mathbf{C}_{1,1}\\) beschreiben) ist die Summe über die elementweisen Multiplikationen der Element in der ersten Zeile von \\(\\mathbf{A}\\) und der ersten Spalte von \\(\\mathbf{B}\\).\nOder allgemeiner: \\(\\mathbf{C}_{i,j} = \\sum_{k=1}^n \\mathbf{A}_{i,k} \\cdot \\mathbf{B}_{k,j}\\).\nAm einfachsten lässt sich das ganze an einem Beispiel anschauen:\n\\[\\begin{align}\n\\begin{pmatrix}\n2 & -3 \\\\\n1 & 2\n\\end{pmatrix}\n\\begin{pmatrix}\n1.3 & -3 & 0 \\\\\n1 & 0.5 & 1\n\\end{pmatrix}\n&=\n\\begin{pmatrix}\n2\\cdot 1.3 + (-3)\\cdot 1\n& 2\\cdot (-3) + (-3)\\cdot 0.5\n& 2\\cdot 0 + (-3)\\cdot 1\n\\\\\n1\\cdot 1.3 + 2\\cdot 1\n& 1\\cdot (-3) + 2\\cdot 0.5\n& 1\\cdot 0 + 2\\cdot 1\n\\end{pmatrix}\\\\\n&=\n\\begin{pmatrix}\n-0.4 & -7.5 & -3 \\\\\n3.3 & -2 & 2\n\\end{pmatrix}.\n\\end{align}\\]\n\n\n\nFür unser einfaches Beispiel kann das Modell wie folgt in Matrixform geschrieben werden:\n\\[\\begin{align}\nf(\\mathbf{X}) &= \\mathbf{X}\\mathbf{w}\\\\\n&= \\begin{pmatrix}\n1 & -4.1 \\\\\n1 & -0.5 \\\\\n1 & 1.4 \\\\\n1 & 4.4 \\\\\n\\end{pmatrix}\\begin{pmatrix} w_0 \\\\ w_1 \\end{pmatrix}\\\\\n&= \\begin{pmatrix}\nw_0 \\cdot 1 - w_1 \\cdot 4.1 \\\\\nw_0 \\cdot 1 - w_1 \\cdot 0.5 \\\\\nw_0 \\cdot 1 + w_1 \\cdot 1.4 \\\\\nw_0 \\cdot 1 + w_1 \\cdot 4.4 \\end{pmatrix}\n\\end{align}\\]\nWarum wir all das tun, werden wir weiter unten sehen. Es wird unser Leben viel einfacher machen! Versuchen Sie diesen Abschnitt hier gut zu verstehen, so dass Sie sobald wie möglich mit der Matrixschreibweise von Modellen vertraut sind.",
    "crumbs": [
      "Klassisches Machine Learning",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Lineare Regression</span>"
    ]
  },
  {
    "objectID": "02_linreg.html#modelltraining",
    "href": "02_linreg.html#modelltraining",
    "title": "2  Lineare Regression",
    "section": "2.4 Modelltraining",
    "text": "2.4 Modelltraining\nWir werden uns hier anschauen, wie für das Training (oft auch Fitting genannt) des linearen Regressionsmodells zwei verschiedene Perspektiven eingenommen werden können, welche am Schluss beide zum selben Resultat führen.\n\n2.4.1 Perspektive 1: Funktionsoptimierung\nIn der ersten Perspektive behandeln wir das Modelltraining als Optimierungsproblem. Wir wollen nämlich eine sogenannte Kostenfunktion (engl. Loss Function) aufstellen, die es danach zu minimieren gilt. Sie werden gleich sehen, dass die Kostenfunktion für das lineare Regressionsmodell von den Modellparameter \\(w_0,w_1,\\dots,w_p\\) abhängt. Das Ziel wird also sein, die optimalen Werte für die Modellparameter zu finden, so dass die Kostenfunktion so klein wie möglich ist.\nDoch wie sieht denn nun diese Kostenfunktion für das lineare Regressionsmodell konkret aus? Wir werden uns hier der Einfachheit halber nur ein einfaches lineares Regressionsmodell mit nur einer Input-Variable \\(x_i\\) anschauen (wie in unserem einfachen Beispiel). Die Kostenfunktion sieht in diesem Fall so aus:\n\\[\nJ(\\hat{w}_0,\\hat{w}_1) = \\frac{1}{2n} \\sum_{i=1}^{n} \\left(y_i - \\hat{f}(x_i) \\right)^2\n\\]\nSie sehen, dass die Kostenfunktion \\(J(\\hat{w}_0,\\hat{w}_1)\\) eine Funktion der beiden (trainierten) Modellparameter ist. Vielleicht wundern Sie sich nun, wie diese Kostenfunktion von den Modellparameter abhängt, da diese in obiger Formel ja gar nicht direkt ersichtlich sind. Schreiben wir die Kostenfunktion doch mal etwas um:\n\\[\\begin{align}\nJ(\\hat{w}_0, \\hat{w}_1) &= \\frac{1}{2n} \\sum_{i=1}^{n} \\left(y_i - \\hat{f}(x_i) \\right)^2 \\\\\n&= \\frac{1}{2n} \\sum_{i=1}^{n} \\left(y_i - (\\hat{w}_0 + \\hat{w}_1 \\cdot x_i) \\right)^2 \\\\\n&= \\frac{1}{2n} \\sum_{i=1}^{n} \\left(y_i - \\hat{w}_0 - \\hat{w}_1 \\cdot x_i \\right)^2 \\\\\n\\end{align}\\]\nNun ist offensichtlich, wie die Kostenfunktion \\(J\\) von den Modellparameter \\(\\hat{w}_0\\) und \\(\\hat{w}_1\\) abhängt. Im ML gibt es nun viele verschiedene Arten, wie man für die beiden Modellparameter die optimalen Werte findet. Hier ist die Lösung zum Glück einfach, denn es gibt eine sogenannte analytische Lösung, d.h. es ist möglich für \\(\\hat{w}_0\\) und \\(\\hat{w}_1\\) je eine Formel zu finden, die uns erlaubt die optimalen Parameterwerte direkt auszurechnen. Die Herleitung dieser Formeln ist nicht besonders schwierig, denn wir wenden nämlich ein altbekanntes Prinzip aus der Differenzialrechnung an: wir berechnen die erste Ableitung der Funktion nach den Modellparameter, setzen sie gleich Null und lösen nach dem Parameter auf.\nIm folgenden Matheteil sehen Sie, wie wir die Formeln für die Berechnung der optimalen Parameterwerte des einfachen linearen Regressionsmodells herleiten können. Diese Methode wird Kleinstquadratemethode (engl. Least Squares) genannt, weil die optimalen Parameter die Summe über die quadrierten Differenzen zwischen \\(y_i\\) und den Vorhersagen \\(\\hat{f}(x_i)\\) minimieren.\n\n\n\n\n\n\nVorsichtKleinstquadratemethode\n\n\n\n\n\nWir leiten zuerst die Formel für \\(\\hat{w}_0\\) her:\n\\[\\begin{align}\n\\frac{\\partial J(\\hat{w}_0, \\hat{w}_1)}{\\partial \\hat{w}_0} &= \\frac{1}{2n} \\sum_{i=1}^{n} 2 \\cdot \\left(y_i - \\hat{w}_0 - \\hat{w}_1 \\cdot x_i \\right) \\cdot (-1) \\\\\n&= -\\frac{1}{n} \\sum_{i=1}^{n} \\left(y_i - \\hat{w}_0 - \\hat{w}_1 \\cdot x_i \\right) \\\\\n&= -\\frac{1}{n} \\sum_{i=1}^{n} y_i +  \\frac{1}{n} \\sum_{i=1}^{n} \\hat{w}_0 + \\frac{1}{n} \\sum_{i=1}^{n} \\hat{w}_1 \\cdot x_i \\\\\n&= -\\bar{y} + \\frac{1}{n} \\cdot n \\cdot \\hat{w}_0 + \\hat{w}_1 \\cdot \\bar{x} \\\\\n&= -\\bar{y} + \\hat{w}_0 + \\hat{w}_1 \\cdot \\bar{x}\n\\end{align}\\]\nNun setzten wir die Ableitung gleich Null und lösen nach \\(\\hat{w}_0\\) auf:\n\\[\\begin{align}\n-\\bar{y} + \\hat{w}_0 + \\hat{w}_1 \\cdot \\bar{x} &= 0 \\\\\n\\hat{w}_0 &= \\bar{y} - \\hat{w}_1 \\cdot \\bar{x}\n\\end{align}\\]\nWir sehen, dass die Lösung für \\(\\hat{w}_0\\) von den beiden Mittelwerten \\(\\bar{y}\\) und \\(\\bar{x}\\) sowie von \\(\\hat{w}_1\\) abhängt. Suchen wir nun also in einem zweiten Schritt die Lösung für \\(\\hat{w}_1\\):\n\\[\\begin{align}\n\\frac{\\partial J(\\hat{w}_0, \\hat{w}_1)}{\\partial \\hat{w}_1} &= \\frac{1}{2n} \\sum_{i=1}^{n} 2 \\cdot \\left(y_i - \\hat{w}_0 - \\hat{w}_1 \\cdot x_i \\right) \\cdot (-x_i) \\\\\n&= -\\frac{1}{n} \\sum_{i=1}^{n} \\left(y_i \\cdot x_i - \\hat{w}_0 \\cdot x_i - \\hat{w}_1 \\cdot x_i^2 \\right) \\\\\n&= -\\frac{1}{n} \\sum_{i=1}^{n} y_i \\cdot x_i + \\hat{w}_0 \\cdot \\frac{1}{n} \\sum_{i=1}^{n} x_i + \\hat{w}_1 \\cdot \\frac{1}{n} \\sum_{i=1}^{n} x_i^2 \\\\\n&= -\\frac{1}{n} \\sum_{i=1}^{n} y_i \\cdot x_i + \\hat{w}_0 \\cdot \\bar{x} + \\hat{w}_1 \\cdot \\frac{1}{n} \\sum_{i=1}^{n} x_i^2 \\\\\n\\end{align}\\]\nNun können wir wiederum die Ableitung gleich Null setzen und für \\(\\hat{w}_0\\) setzen wir unsere Lösung von oben ein. Danach lösen wir nach \\(\\hat{w}_1\\) auf:\n\\[\\begin{align}\n-\\frac{1}{n} \\sum_{i=1}^{n} y_i \\cdot x_i + \\hat{w}_0 \\cdot \\bar{x} + \\hat{w}_1 \\cdot \\frac{1}{n} \\sum_{i=1}^{n} x_i^2 &= 0 \\\\\n(\\bar{y} - \\hat{w}_1 \\cdot \\bar{x}) \\cdot \\bar{x} + \\hat{w}_1 \\cdot \\frac{1}{n} \\sum_{i=1}^{n} x_i^2 &= \\frac{1}{n} \\sum_{i=1}^{n} y_i \\cdot x_i \\\\\n\\bar{y} \\cdot \\bar{x} - \\hat{w}_1 \\cdot \\bar{x}^2 + \\hat{w}_1 \\cdot \\frac{1}{n} \\sum_{i=1}^{n} x_i^2 &= \\frac{1}{n} \\sum_{i=1}^{n} y_i \\cdot x_i \\\\\n\\hat{w}_1 \\left(\\frac{1}{n} \\sum_{i=1}^{n} x_i^2 - \\bar{x}^2 \\right) &= \\frac{1}{n} \\sum_{i=1}^{n} y_i \\cdot x_i - \\bar{y} \\cdot \\bar{x} \\\\\n\\hat{w}_1 &= \\frac{\\frac{1}{n} \\sum_{i=1}^{n} y_i \\cdot x_i - \\bar{y} \\cdot \\bar{x}}{\\frac{1}{n} \\sum_{i=1}^{n} x_i^2 - \\bar{x}^2}\n\\end{align}\\]\nVielleicht erkennen Sie die Ausdrücke im Zähler und Nenner der Lösung für \\(\\hat{w}_1\\): es sind dies die Kovarianz zwischen \\(y_i\\) und \\(x_i\\) im Zähler und die Varianz von \\(x_i\\) im Nenner. Man kan die Formel also auch wie folgt aufschreiben:\n\\[\n\\hat{w}_1 = \\frac{\\text{Cov}(x, y)}{\\text{Var}(x)}\n\\]\n\n\n\n\nFrage\nRechnen Sie nun die optimalen Parameterwerte für unser einfaches lineares Regressionsmodell aus. Sie können die verschiedenen statistischen Grössen entweder mithilfe von R rechnen oder von Hand bzw. mit dem Taschenrechner.\n\n\n\n\n\n\nTippLösung\n\n\n\n\n\nWir rechnen als erstes die Mittelwerte für die beiden Variablen:\n\\[\n\\bar{x} = \\frac{-4.1 + (-0.5) + 1.4 + 4.4}{4} = 0.3\n\\]\n\\[\n\\bar{y} = \\frac{3.50 + 1.95 + (-2.50) + (-2.05)}{4} = 0.225\n\\]\nDanach rechnen wir die mittlere Summe über die Produkte der jeweiligen Variablenwerte (erster Teil des Zählers der Formel für \\(\\hat{w}_1\\)):\n\\[\n\\frac{3.50 \\cdot (-4.1) + 1.95 \\cdot (-0.5) + (-2.50) \\cdot 1.4 + (-2.05) \\cdot 4.4}{4}\n= -6.96125\n\\]\nNun rechnen wir die mittlere Summe über die quadrierten \\(x\\)-Werte (erster Teil des Nenners der Formel für \\(\\hat{w}_1\\)):\n\\[\n\\frac{(-4.1)^2 + (-0.5)^2 + 1.4^2 + 4.4^2}{4} = 9.595\n\\]\nNun können wir den optimalen Parameterwert für \\(\\hat{w}_1\\) berechnen:\n\\[\n\\hat{w}_1 = \\frac{-6.96125 - 0.225 \\cdot 0.3}{9.595 - 0.3^2} = -0.7395\n\\]\nUnd nun haben wir auch gleich alle Zutaten, um den optimalen Parameterwert für \\(\\hat{w}_0\\) zu berechnen:\n\\[\n\\hat{w}_0 = 0.225 - (-0.7395) \\cdot 0.3 = 0.4469\n\\]\nUnser trainiertes optimales Modell sieht also wie folgt aus:\n\\[\n\\hat{f}(x_i) = 0.4469 - 0.7395 \\cdot x_i\n\\]\n\n\n\nDas in der obigen Aufgabe berechnete Modell ist in der folgenden Abbildung (links) grafisch als blaue Gerade dargestellt. Der Parameter \\(\\hat{w}_0\\) ist der Ort, an dem die Gerade die y-Achse durchkreuzt, während der Parameter \\(\\hat{w}_1\\) der Steigung der Geraden entspricht. Unser optimales Modell minimiert die Summe über die quadrierten Differenzen zwischen den tatsächlichen \\(y_i\\) Werten und den Vorhersagen gemäss unserem Modell \\(\\hat{f}(x_i)\\) (die Differenzen sind als rot gestrichelte Linien eingetragen).\n\n\n\n\n\nEinfaches Regressionsbeispiel. Das geschätzte Modell ist als blaue Gerade eingezeichnet. Die vertikalen roten Linien stellen die Abweichungen der wahren Outputs von den Vorhersagen dar. Rechts ist ein Konturplot der Kostenfunktion mit der optimalen Parameterwert-Kombination dargestellt.\n\n\n\n\nDie Abbildung (rechts) zeigt sogennante Konturlinien unserer Kostenfunktion. Die optimale Parameterwert-Kombination ist als roter Punkt eingezeichnet. Jede Konturlinie zeigt alle Parameterwert-Kombination, welche jeweils zum gleichen Kostenwert führen. Die fünf eingezeichneten Linien zeigen beispielsweise die Parameterwert-Kombination für die Kostenwerte 1 bis 5 (von innen nach aussen). Man kann sich unsere Kostenfunktion also wie eine Schüssel vorstellen mit dem roten Punkt als Boden der Schüssel. Es handelt sich bei unserer Kostenfunktion um eine Funktion, die quadratisch in den Parameterwerten \\(\\hat{w}_0\\) und \\(\\hat{w}_1\\) ist. In diesem Fall finden wir immer genau eine Parameterwert-Kombination, welche dem absoluten Minimum der Kostenfunktion entspricht. Manchmal spricht man auch von einer konvexen Kostenfunktion.\n\n\n\n\n\n\nVorsichtKleinstquadratemethode in Matrixform (optional)\n\n\n\n\n\nDie obige Herleitung funktioniert nur für das einfache lineare Regressionsmodell mit einer Input-Variable \\(x_i\\). Wir schauen uns hier nun kurz die allgemeine Lösung in Matrixform an. Wir nehmen an, dass die Werte unseres Outputs alle in einem Spaltenvektor \\(\\mathbf{y}\\) organisiert sind und unsere Modellvorhersagen als \\(\\mathbf{X}\\mathbf{\\hat{w}}\\) geschrieben werden können.\nDann können wir unsere Kostenfunktion von oben wie folgt in Matrixform schreiben:\n\\[\\begin{align}\nJ(\\mathbf{\\hat{w}}) &= \\frac{1}{2n} (\\mathbf{y} - \\mathbf{X}\\mathbf{\\hat{w}})' (\\mathbf{y} - \\mathbf{X}\\mathbf{\\hat{w}})\n\\end{align}\\]\nDas sieht schlimmer aus als es ist, denn \\((\\mathbf{y} - \\mathbf{X}\\mathbf{\\hat{w}})\\) ist lediglich ein Spaltenvektor mit den Differenzen zwischen den wahren \\(y_i\\) und den Vorhersagen unseres Modells. Wenn wir diesen Spaltenvektor \\(\\mathbf{e}\\) nennen, dann kann obiger Ausdruck als \\(\\frac{1}{2n} \\mathbf{e}'\\mathbf{e}\\) geschrieben werden, wobei \\(\\mathbf{e}'\\mathbf{e}\\) ein Skalarprodukt ist und dementsprechend einen Skalar bzw. eine einzige Zahl zurück gibt. Diese Zahl multipliziert mit \\(\\frac{1}{2n}\\) ist dann nichts anderes als der Wert unserer Kostenfunktion. Sie sehen also, dass wir mit dem Skalarprodukt \\(\\mathbf{e}'\\mathbf{e}\\) die Summe ersetzen können.\nNun wenden wir die bekannten Matrix-Rechenregeln an, um die Kostenfunktion umzuschreiben:\n\\[\\begin{align}\nJ(\\mathbf{\\hat{w}}) &= \\frac{1}{2n} (\\mathbf{y} - \\mathbf{X}\\mathbf{\\hat{w}})' (\\mathbf{y} - \\mathbf{X}\\mathbf{\\hat{w}}) \\\\\n&= \\frac{1}{2n} (\\mathbf{y}' - \\mathbf{\\hat{w}}' \\mathbf{X}') (\\mathbf{y} - \\mathbf{X}\\mathbf{\\hat{w}}) \\\\\n&= \\frac{1}{2n} (\\mathbf{y}'\\mathbf{y} - \\mathbf{y}'\\mathbf{X}\\mathbf{\\hat{w}} - \\mathbf{\\hat{w}}' \\mathbf{X}'\\mathbf{y} + \\mathbf{\\hat{w}}' \\mathbf{X}'\\mathbf{X}\\mathbf{\\hat{w}})\n\\end{align}\\]\nWenn Sie sich kurz anhand der Dimensionalität der einzelnen Komponenten überlegen, was das Endprodukt des Ausdrucks \\(\\mathbf{y}'\\mathbf{X}\\mathbf{\\hat{w}}\\) ist, dann werden Sie sehen, dass ein Skalar (Dimensionalität \\(1 \\times 1\\)) resultiert. Darum muss zwingend auch die transponierte Form davon, \\((\\mathbf{y}'\\mathbf{X}\\mathbf{\\hat{w}})'=\\mathbf{\\hat{w}}' \\mathbf{X}'\\mathbf{y}\\) ein Skalar sein, was dazu führt, dass die beiden mittleren Terme in der letzten Zeile von obiger Kostenfunktion identisch sein müssen. Deshalb können wir die Kostenfunktion wie folgt umschreiben:\n\\[\\begin{align}\nJ(\\mathbf{\\hat{w}}) &= \\frac{1}{2n} (\\mathbf{y}'\\mathbf{y} - 2\\mathbf{y}'\\mathbf{X}\\mathbf{\\hat{w}} + \\mathbf{\\hat{w}}' \\mathbf{X}'\\mathbf{X}\\mathbf{\\hat{w}})\n\\end{align}\\]\nSo, nun können wir die Kostenfunktion nach dem Spaltenvektor mit den Modellparameter \\(\\mathbf{\\hat{w}}\\) ableiten. Man spricht in diesem Fall nun nicht von einer Ableitung, sondern von einem Gradienten. Auch die mathematische Schreibweise ist etwas anders:\n\\[\\begin{align}\n\\nabla_{\\mathbf{\\hat{w}}} J(\\mathbf{\\hat{w}}) &= \\frac{1}{2n} (- 2\\mathbf{X}'\\mathbf{y} + 2\\mathbf{X}'\\mathbf{X}\\mathbf{\\hat{w}}) \\\\\n&= \\frac{1}{n} (-\\mathbf{X}'\\mathbf{y} + \\mathbf{X}'\\mathbf{X}\\mathbf{\\hat{w}})\n\\end{align}\\]\nDiesen Ausdruck können wir nun wie gewohnt gleich Null setzen (wobei wir hier rechts einen Nullvektor \\(\\mathbf{0}\\) setzen) und mit den Matrix-Rechenregeln nach \\(\\mathbf{\\hat{w}}\\) auflösen:\n\\[\\begin{align}\n\\frac{1}{n} (-\\mathbf{X}'\\mathbf{y} + \\mathbf{X}'\\mathbf{X}\\mathbf{\\hat{w}}) &= \\mathbf{0} \\\\\n\\mathbf{X}'\\mathbf{X}\\mathbf{\\hat{w}} &= \\mathbf{X}'\\mathbf{y} \\\\\n\\mathbf{\\hat{w}} &= (\\mathbf{X}'\\mathbf{X})^{-1}\\mathbf{X}'\\mathbf{y}\n\\end{align}\\]\nWichtig: Die Matrix \\(\\mathbf{X}'\\mathbf{X}\\) hat eine Dimensionalität von \\((p+1) \\times (p+1)\\), ist also quadratisch. Sie ist nur invertierbar, wenn die Design Matrix mehr Zeilen als Spalten hat, also wenn \\(n &gt; (p+1)\\).\n\n\n\n\n\nGütemasse für die Regression\nEine Form der hier verwendeten Kostenfunktion wird oft auch als Gütemass für die Vorhersagen eines Regressionsmodells verwendet. In diesem Zusammenhang sprechen wir dann vom Mean Squared Error (MSE). Mit diesen Gütemassen beurteilen wir die Vorhersagegüte von fertig trainierten Modellen; sie haben also nichts mit dem Training zu tun.\nHäufig wird nicht der MSE sondern der Root Mean Squared Error (RMSE) verwendet, so dass das resultierende Fehlermass auf derselben Skala wie die Vorhersagen “lebt”. Oder anders gesagt, wir neutralisieren den Effekt des Quadrierens wieder. Die Formel für den RMSE sieht wie folgt aus:\n\\[\nRMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} \\left(y_i - \\hat{f}(x_i) \\right)^2}\n\\]\nEine Alternative zum RMSE ist der Mean Absolute Error (MAE), der wie folgt definiert ist:\n\\[\nMAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{f}(x_i)|\n\\] Der MAE hat im Vergleich zum RMSE den Vorteil, dass er wengier stark auf grosse Differenzen zwischen dem wahren und vorhergesagten Wert für \\(y\\) reagiert, oder, in anderen Worten, robuster gegen Ausreisser ist.3\n\n\n\n2.4.2 Perspektive 2: Wahrscheinlichkeitstheorie\nNun werden wir sehen, dass wir die Lösung oben (aus Perspektive 1) auch mit einer probabilistischen Sicht auf die Dinge erhalten. Dazu schreiben wir nochmals kurz den allgemein angenommenen Zusammenhang zwischen dem wahren Output \\(y_i\\) und den Input-Variablen auf und konkretisieren ihn dann gleich für das lineare Regressionsmodell:\n\\[\\begin{align}\ny_i &= f(\\mathbf{x}_i) + \\epsilon \\\\\n&= \\mathbf{w}' \\mathbf{x_i} + \\epsilon \\\\\n\\end{align}\\]\nNun nehmen wir an, dass der Fehlerterm \\(\\epsilon\\) normalverteilt ist mit Mittelwert 0 und Varianz \\(\\sigma^2\\), also \\(\\epsilon \\sim N(0,\\sigma^2)\\). Weil wir annehmen, dass \\(\\mathbf{w}' \\mathbf{x_i}\\) fix ist (also keine Zufallsvariable), ist unser Output \\(y_i\\) normalverteilt mit Mittelwert \\(\\mathbf{w}' \\mathbf{x_i}\\) und Varianz \\(\\sigma^2\\):\n\\[\ny_i \\sim \\mathcal{N}\\left(\\mathbf{w}' \\mathbf{x_i}, \\sigma^2\\right)\n\\]\nFolgende Abbildung illlustriert diese Annahme: an jedem Ort \\(x_i\\) ist der entsprechende Outputwert \\(y_i\\) eine Realisierung (oder Ziehung) aus einer Normalverteilung mit Mittelwert \\(\\mathbf{w}' \\mathbf{x_i}\\) und Varianz \\(\\sigma^2\\).\n\n\n\n\n\n\n\n\n\nNun möchten wir wissen, was die gemeinsame Verteilung aller Output-Werte in unserem Datensatz ist. D.h. wie sieht die Wahrscheinlichkeit \\(p(y_1,y_2,\\dots,y_n|\\mathbf{w},\\mathbf{X},\\sigma^2)\\) aus? Weil wir annehmen, dass alle Beobachtungen \\(i\\) in unserem Datensatz unabhängig sind und die Wahrscheinlichkeiten der einzelnen Beobachtungen \\(i\\) darum multipliziert werden können, sieht die Antwort auf die Frage folgendermassen aus:\n\\[\np(y_1,y_2,\\dots,y_n\\mid\\mathbf{w},\\mathbf{X},\\sigma^2) = \\prod_{i=1}^n \\mathcal{N}\\left(\\mathbf{w}' \\mathbf{x_i}, \\sigma^2\\right)\n\\]\n\n\n\n\n\n\nHinweisMaximum Likelihood\n\n\n\nDie gemeinsame Wahrscheinlichkeit \\(p(y_1,y_2,\\dots,y_n\\mid\\mathbf{w},\\mathbf{X},\\sigma^2)\\) der beobachteten Output-Werte, gegeben die Input-Werte und das Modell (charakterisiert durch dessen Parameter \\(\\mathbf{w}\\) und \\(\\sigma^2\\)), wird in der Fachsprache Likelihood genannt.\nDie zentrale Idee hier ist, dass wir die Modellparameter \\(\\mathbf{w}\\) so wählen, dass die Likelihood maximal wird. Der daraus folgende Ausdruck für \\(\\mathbf{w}\\) wird Maximum Likelihood Schätzer genannt und oft als ML abgekürzt, was sehr verwirrlich sein kann, da wir ja auch Machine Learning so abkürzen.\nMit dem ML-Schätzer finden wir also dasjenige (lineare) Modell (bzw. dessen Parameterwerte), das die beobachteten \\(y_i\\)-Werte maximal wahrscheinlich macht.\n\n\n\n\n\n\n\n\nVorsichtMaximum Likelihood Herleitung (optional)\n\n\n\n\n\nWir können nun in der Likelihood oben anstelle von \\(\\mathcal{N}\\left(\\mathbf{w}' \\mathbf{x_i}, \\sigma^2\\right)\\) jeweils die Dichtefunktion der Normalverteilung einsetzen:\n\\[\\begin{align}\np(y_1,y_2,\\dots,y_n|\\mathbf{w},\\mathbf{X},\\sigma^2) &= \\prod_{i=1}^n \\mathcal{N}\\left(\\mathbf{w}' \\mathbf{x_i}, \\sigma^2\\right) \\\\\n&= \\prod_{i=1}^n \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left( -\\frac{1}{2}\\left(\\frac{y_i - \\mathbf{w}' \\mathbf{x_i}}{\\sigma}\\right)^{\\!2}\\,\\right)\n\\end{align}\\]\nNun vollziehen wir einen kleinen mathematischen Trick, der vielfach angewendet wird: anstelle der Likelihood verwenden wir nun den natürlichen Logarithmus der Likelihood (Log-Likelihood). Das ist möglich, weil sich so das Optimierungsproblem nicht verändert. Das Logarithmieren vereinfacht das Problem ungemein, denn der Logarithmus eines Produkts wird zu einer Summe der logarithmierten Elemente:\n\\[\\begin{align}\n\\text{ln}\\; p(y_1,y_2,\\dots,y_n|\\mathbf{w},\\mathbf{X},\\sigma^2) &= \\text{ln}\\left(\\prod_{i=1}^n \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left( -\\frac{1}{2}\\left(\\frac{y_i - \\mathbf{w}' \\mathbf{x_i}}{\\sigma}\\right)^{\\!2}\\,\\right)\\right) \\\\\n&= \\sum_{i=1}^n \\text{ln}\\left(\\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left( -\\frac{1}{2}\\left(\\frac{y_i - \\mathbf{w}' \\mathbf{x_i}}{\\sigma}\\right)^{\\!2}\\,\\right) \\right) \\\\\n&= \\sum_{i=1}^n \\text{ln}\\left(1\\right) - \\text{ln}\\left(\\sigma\\sqrt{2\\pi}\\right) - \\frac{1}{2}\\left(\\frac{y_i - \\mathbf{w}' \\mathbf{x_i}}{\\sigma}\\right)^{\\!2} \\\\\n&= \\sum_{i=1}^n \\text{ln}\\left(1\\right) - \\sum_{i=1}^n \\text{ln}\\left(\\sigma\\sqrt{2\\pi}\\right) - \\sum_{i=1}^n \\frac{1}{2}\\left(\\frac{y_i - \\mathbf{w}' \\mathbf{x_i}}{\\sigma}\\right)^{\\!2} \\\\\n&= n \\cdot \\text{ln}\\left(1\\right) - n \\cdot \\text{ln}\\left(\\sigma\\sqrt{2\\pi}\\right) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^n \\left(y_i - \\mathbf{w}' \\mathbf{x_i}\\right)^{\\!2}\n\\end{align}\\]\nWow, nun haben wir ein tolles Resultat gefunden: je kleiner der Term \\(\\sum_{i=1}^n \\left(y_i - \\mathbf{w}' \\mathbf{x_i}\\right)^{\\!2}\\) in obiger Gleichung, desto grösser ist der natürliche Logarithmus der Likelihood. Das heisst nichts anderes, als dass die Kleinstquadratemethode auch der Maximum Likelihood Schätzer ist.\nWir haben mit der Annahme begonnen, dass unser Output \\(y_i\\) normalverteilt ist, d.h. \\(y_i \\sim \\mathcal{N}\\left(\\mathbf{w}' \\mathbf{x_i}, \\sigma^2\\right)\\). Wir haben nun herausgefunden, dass der mit der Kleinstquadratemethode berechnete Vektor \\(\\mathbf{w}\\) auch glech dem ML-Schätzer entspricht. Um die Normalverteilung vollkommen zu spezifizieren, benötigen wir nun noch eine Formel, um die Varianz \\(\\sigma^2\\) zu rechnen. Dazu leiten wir den obigen Ausdruck der Log-Likelihood nach \\(\\sigma\\) ab:\n\\[\\begin{align}\n\\frac{\\partial \\text{ln}\\; p(y_1,y_2,\\dots,y_n|\\mathbf{w},\\mathbf{X},\\sigma^2)}{\\partial \\sigma} &= -n\\cdot \\frac{\\sqrt{2\\pi}}{\\sigma\\sqrt{2\\pi}} - (-\\frac{2}{\\sigma^3}) \\cdot \\frac{1}{2} \\sum_{i=1}^n \\left(y_i - \\mathbf{w}' \\mathbf{x_i}\\right)^{\\!2} \\\\\n&= -\\frac{n}{\\sigma} + \\frac{1}{\\sigma^3} \\sum_{i=1}^n \\left(y_i - \\mathbf{w}' \\mathbf{x_i}\\right)^{\\!2}\n\\end{align}\\]\nNun können wir wie gewohnt die Ableitung gleich Null setzen und nach \\(\\sigma\\) auflösen:\n\\[\\begin{align}\n-\\frac{n}{\\hat{\\sigma}} + \\frac{1}{\\hat{\\sigma}^3} \\sum_{i=1}^n \\left(y_i - \\mathbf{\\hat{w}}' \\mathbf{x_i}\\right)^{\\!2} &= 0 \\\\\n\\frac{n}{\\hat{\\sigma}} &= \\frac{1}{\\hat{\\sigma}^3} \\sum_{i=1}^n \\left(y_i - \\mathbf{\\hat{w}}' \\mathbf{x_i}\\right)^{\\!2} \\\\\n\\frac{\\hat{\\sigma}^3}{\\hat{\\sigma}} &= \\frac{1}{n} \\sum_{i=1}^n \\left(y_i - \\mathbf{\\hat{w}}' \\mathbf{x_i}\\right)^{\\!2} \\\\\n\\hat{\\sigma}^2 &= \\frac{1}{n} \\sum_{i=1}^n \\left(y_i - \\mathbf{\\hat{w}}' \\mathbf{x_i}\\right)^{\\!2} \\\\\n\\end{align}\\]\nSehr schön, dieses Resultat macht ebenfalls viel Sinn. Die geschätzte Varianz \\(\\hat{\\sigma}^2\\) ist nichts anderes als der durchschnittliche quadrierte Fehler (engl. Mean Squared Error).",
    "crumbs": [
      "Klassisches Machine Learning",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Lineare Regression</span>"
    ]
  },
  {
    "objectID": "02_linreg.html#regularisierte-regression",
    "href": "02_linreg.html#regularisierte-regression",
    "title": "2  Lineare Regression",
    "section": "2.5 Regularisierte Regression",
    "text": "2.5 Regularisierte Regression\nDas zentrale Problem der oben kennen gelernten Kleinstquadratemethode ist, dass sie extrem anfällig auf Overfitting ist. Vereinfacht gesagt bedeutet Overfitting, dass sich das Modell zu fest an die Trainingsdaten anpasst und die aus den Daten gelernten Muster nicht mehr generalisierbar sind.\nBeim linearen Regressionsmodell ist Overfitting vor allem dann ein Problem, wenn die Anzahl Input-Variablen \\(p\\) relativ gross ist im Vergleich zur Anzahl Beobachtungen \\(n\\). Im Extremfall haben wir mehr Input-Variablen als Beobachtungen (\\((p+1)&gt;n\\)), was dazu führt, dass der Kleinstquadrateschätzer mathematisch nicht rechenbar ist.4 Das sollte auch intuitiv Sinn machen, denn wie soll eine Schätzung funktionieren, wenn wir im Schnitt weniger als eine Beobachtung pro zu schätzenden Parameter haben.\nWir können das Problem des Overfittings weitgehend lösen, indem wir ein regularisiertes Regressionsmodell rechnen. Regularisierung bedeutet eigentlich nichts anderes, als dass wir die ursprüngliche Kostenfunktion für das lineare Regressionsmodell modifizieren. Dabei gibt es zwei bekannte Regularisierungsarten, nämlich Ridge oder LASSO. Wir fokussieren in einem ersten Schritt auf die Ridge Regularisierung, weil wir in diesem Fall wiederum eine analytische Lösung finden.\n\n2.5.1 Ridge Regressionsmodell\nDie Kostenfunktion für das Ridge Regressionsmodell sieht wie folgt aus:\n\\[\nJ(\\mathbf{w}) = \\frac{1}{2n} \\sum_{i=1}^{n} \\left(y_i - \\hat{f}(\\mathbf{x}_i) \\right)^2 + \\frac{\\lambda}{2} \\cdot \\sum_{j=1}^p w_j^2\n\\]\nDiese modifizierte Kostenfunktion hat etwas Erklärungsbedarf:\n\nWir versuchen hier Modellparameter \\(\\mathbf{w}\\) zu finden, welche gleichzeitig den durchschnittlichen quadrierten Fehler sowie eine Summe über die quadrierten Modellparameter so klein wie möglich machen. Das sind zwei konkurrenzierende Ziele und während des Modelltrainings muss der beste Tradeoff gefunden werden.\nDer Regularisierungsterm ist eine Summe über die quadrierten Modellparameter. Das Quadrieren stellt sicher, dass sich positive und negative Parameterwerte nicht gegenseitig kompensieren.\nDer Hyperparameter \\(\\lambda\\) legt fest, wie viel (relatives) Gewicht der Regularisierungsterm im Verhältnis zum durchschnittlichen quadrierten Fehler bekommt. Je grösser \\(\\lambda\\), desto stärker “bestrafen” wir komplexe Modelle. Wir werden später sehen, wir wir den optimalen Wert für \\(\\lambda\\) via Cross-Validation finden können.\nDer Regularisierungsterm enthält die Konstante \\(w_0\\) nicht (die Summe startet bei \\(j=1\\) und nicht bei \\(j=0\\)). Die Konstante des Modells wird also nie regularisiert, denn sie definiert lediglich den Punkt, wo die Gerade (oder die Hyperebene im Fall von mehr als einer Input-Variable) die y-Achse schneidet. Dieser Parameter soll flexibel bleiben.\n\n\nFragen\n\nWas passiert wenn \\(\\lambda=0\\)?\nWas passiert wenn \\(\\lambda \\rightarrow \\infty\\)?\n\n\n\n\n\n\n\nTippLösung\n\n\n\n\n\n\nWenn \\(\\lambda=0\\), dann entfällt der Regularisierungsterm und wir haben die altbekannte Kostenfunktion. Die resultierenden Parameter entsprechen dem Kleinstquadrateschätzer.\nWenn \\(\\lambda \\rightarrow \\infty\\), dann wird der Regularisierungsterm so wichtig, dass alle Gewichte \\(w_1,\\dots, w_p\\) auf 0 gesetzt werden. Es resultiert folgendes Modell: \\(\\hat{f}(\\mathbf{x_i}) = \\hat{w}_0\\).\n\n\n\n\nBerechnen Sie hier nun den optimalen Parameter \\(\\hat{w}_1\\) für ein einfaches regularisiertes Regressionsmodell mit nur einer \\(x_i\\)-Variable.\n\nLeiten Sie dazu die obige Kostenfunktion nach \\(\\hat{w}_1\\) ab, setzen Sie sie gleich Null und lösen Sie nach \\(\\hat{w}_1\\) auf.\nFür \\(\\hat{w}_0\\) können Sie die Lösung aus dem unregularisierten Fall einsetzen, also \\(\\hat{w}_0 = \\bar{y} - \\hat{w}_1 \\cdot \\bar{x}\\).\n\n\n\n\n\n\n\nTippLösung\n\n\n\n\n\nDie Kostenfunktion für das einfache regularisierte Modell sieht konkret wie folgt aus:\n\\[\n\\begin{aligned}\nJ(\\hat{w}_0, \\hat{w}_1) &= \\frac{1}{2n} \\sum_{i=1}^{n} \\left(y_i - \\hat{w}_0 - \\hat{w}_1 \\cdot x_i \\right)^2 + \\frac{\\lambda}{2} \\hat{w}_1^2\n\\end{aligned}\n\\]\nNun leiten wir diese Kostenfunktion nach \\(\\hat{w}_1\\) ab und gehen durch sehr ähnliche Schritte wie im unregularisierten Fall:\n\\[\n\\begin{aligned}\n\\frac{\\partial J(\\hat{w}_0, \\hat{w}_1)}{\\partial \\hat{w}_1} &= \\frac{1}{2n} \\sum_{i=1}^{n} 2 \\cdot \\left(y_i - \\hat{w}_0 - \\hat{w}_1 \\cdot x_i \\right) \\cdot (-x_i) + \\frac{2\\lambda}{2} \\hat{w}_1 \\\\[6pt]\n&= -\\frac{1}{n} \\sum_{i=1}^{n} \\left(y_i x_i - \\hat{w}_0 x_i - \\hat{w}_1 x_i^2 \\right) + \\lambda \\hat{w}_1 \\\\[6pt]\n&= -\\frac{1}{n} \\sum_{i=1}^{n} y_i x_i + \\hat{w}_0 \\bar{x} + \\hat{w}_1 \\cdot \\frac{1}{n} \\sum_{i=1}^{n} x_i^2 + \\lambda \\hat{w}_1 \\\\[6pt]\n&= -\\frac{1}{n} \\sum_{i=1}^{n} y_i x_i + (\\bar{y} - \\hat{w}_1 \\bar{x}) \\cdot \\bar{x} + \\hat{w}_1 \\cdot \\frac{1}{n} \\sum_{i=1}^{n} x_i^2 + \\lambda \\hat{w}_1 \\\\[6pt]\n&= -\\frac{1}{n} \\sum_{i=1}^{n} y_i x_i + \\bar{y}\\bar{x} - \\hat{w}_1 \\bar{x}^2 + \\hat{w}_1 \\cdot \\frac{1}{n} \\sum_{i=1}^{n} x_i^2 + \\lambda \\hat{w}_1\n\\end{aligned}\n\\]\nNun setzen wir die Ableitung gleich Null und lösen nach \\(\\hat{w}_1\\) auf:\n\\[\n\\begin{aligned}\n-\\frac{1}{n} \\sum_{i=1}^{n} y_i x_i + \\bar{y}\\bar{x} - \\hat{w}_1 \\bar{x}^2 + \\hat{w}_1 \\cdot \\frac{1}{n} \\sum_{i=1}^{n} x_i^2 + \\lambda \\hat{w}_1 &= 0 \\\\[6pt]\n-\\hat{w}_1 \\bar{x}^2 + \\hat{w}_1 \\cdot \\frac{1}{n} \\sum_{i=1}^{n} x_i^2 + \\lambda \\hat{w}_1 &= \\frac{1}{n} \\sum_{i=1}^{n} y_i x_i - \\bar{y}\\bar{x} \\\\[6pt]\n\\hat{w}_1 \\left( \\frac{1}{n} \\sum_{i=1}^{n} x_i^2 - \\bar{x}^2 + \\lambda \\right) &= \\frac{1}{n} \\sum_{i=1}^{n} y_i x_i - \\bar{y}\\bar{x} \\\\[6pt]\n\\hat{w}_1 &= \\frac{\\mathrm{Cov}(y,x)}{\\mathrm{Var}(x) + \\lambda}\n\\end{aligned}\n\\]\nHa, das macht ja irgendwie Sinn. Je größer der Wert für \\(\\lambda\\), desto grösser der Nenner und desto stärker wird der trainierte Wert für \\(\\hat{w}_1\\) beschränkt.\n\n\n\n\n\n\n\n\n\nVorsichtRidge Regression in Matrixform (optional)\n\n\n\n\n\nDer Einfachheit halber nehmen wir hier an, dass die Outputwerte \\(y_i\\) hier standardisiert5 wurden, so dass der Mittelwert über die standardisierten Outputwerte Null ist. So entfällt die Konstante \\(w_0\\) aus dem Modell, was uns die Matrixform für das Ridge Modell erleichtert, denn der Regularisierungsterm soll ja die Konstante nicht enthalten und wenn es diese nicht gibt, dann gibt es keine Probleme.\nWie weiter oben gesehen, können wir die Kostenfunktion für das nicht-regularisierte Modell wie folgt schreiben:\n\\[\\begin{align}\nJ(\\mathbf{\\hat{w}}) &= \\frac{1}{2n} (\\mathbf{y}'\\mathbf{y} - 2\\mathbf{y}'\\mathbf{X}\\mathbf{\\hat{w}} + \\mathbf{\\hat{w}}' \\mathbf{X}'\\mathbf{X}\\mathbf{\\hat{w}})\n\\end{align}\\]\nDer Regularisierungsterm kann sehr einfach in Matrixform geschrieben werden, nämlich als Skalarprodukt \\(\\frac{\\lambda}{2}\\mathbf{\\hat{w}}'\\mathbf{\\hat{w}}\\). Damit kriegen wir folgende Kostenfunktion:\n\\[\\begin{align}\nJ(\\mathbf{\\hat{w}}) &= \\frac{1}{2n} (\\mathbf{y}'\\mathbf{y} - 2\\mathbf{y}'\\mathbf{X}\\mathbf{\\hat{w}} + \\mathbf{\\hat{w}}' \\mathbf{X}'\\mathbf{X}\\mathbf{\\hat{w}}) + \\frac{\\lambda}{2}\\mathbf{\\hat{w}}'\\mathbf{\\hat{w}}\n\\end{align}\\]\nUm den Gradienten dieser Kostenfunktion zu finden, gehen wir nun sehr ähnlich wie oben vor:\n\\[\\begin{align}\n\\nabla_{\\mathbf{\\hat{w}}} J(\\mathbf{\\hat{w}}) &= \\frac{1}{2n} (- 2\\mathbf{X}'\\mathbf{y} + 2\\mathbf{X}'\\mathbf{X}\\mathbf{\\hat{w}}) + \\frac{2\\lambda}{2}\\mathbf{\\hat{w}} \\\\\n&= \\frac{1}{n} (-\\mathbf{X}'\\mathbf{y} + \\mathbf{X}'\\mathbf{X}\\mathbf{\\hat{w}}) + \\lambda \\mathbf{\\hat{w}}\n\\end{align}\\]\nDiesen Ausdruck können wir nun wie gewohnt gleich Null setzen und mit den Matrix-Rechenregeln nach \\(\\mathbf{\\hat{w}}\\) auflösen:\n\\[\\begin{align}\n\\frac{1}{n} (-\\mathbf{X}'\\mathbf{y} + \\mathbf{X}'\\mathbf{X}\\mathbf{\\hat{w}}) + \\lambda \\mathbf{\\hat{w}} &= \\mathbf{0} \\\\\n\\mathbf{X}'\\mathbf{X}\\mathbf{\\hat{w}} + \\lambda \\mathbf{\\hat{w}} &= \\mathbf{X}'\\mathbf{y} \\\\\n(\\mathbf{X}'\\mathbf{X} + \\lambda \\mathbf{I}) \\mathbf{\\hat{w}} &= \\mathbf{X}'\\mathbf{y} \\\\\n\\mathbf{\\hat{w}} &= (\\mathbf{X}'\\mathbf{X} + \\lambda \\mathbf{I})^{-1}\\mathbf{X}'\\mathbf{y} \\\\\n\\end{align}\\]\nWichtig: \\((\\mathbf{X}'\\mathbf{X} + \\lambda \\mathbf{I})\\) ist immer invertierbar, auch wenn \\(p&gt;n\\). Wir haben nun also ein analytisch lösbares Regressionsmodell gefunden, dass gut gegen Overfitting schützt.\n\n\n\n\n\n\n\n\n\nHinweisStandardisierung der Input-Variablen\n\n\n\nEs ist eminent wichtig, dass Sie alle numerischen Input-Variablen vor der Anwendung eines regularisierten Modells standardisieren, so dass alle Variablen auf der selben Skala “leben”. Warum ist das so wichtig? Sie haben gesehen, dass wir beim Ridge Modell die Grösse der Parameter mit dem Regularisierungsterm beschränken. Wenn jedoch die Input-Variablen alle auf unterschiedlichen Skalen “leben”, dann sind die Parameter nur schon deshalb unterschiedlich. Durch die Standardisierung der Input-Variablen erreichen wir, dass die Parametergrössen vergleichbar werden und die Regularisierung so auch korrekt funktioniert.\n\n\n\n\n\n2.5.2 LASSO Regressionsmodell\nBeim LASSO6 Modell verwenden wir einen anderen Regularisierungsterm als bei Ridge. Anstatt die Parameter zu quadrieren (um Kompensationseffekte zu vermeiden), verwenden wir den absoluten Wert, d.h. wir ignorieren die Vorzeichen der Parameter:\n\\[\nJ(\\mathbf{w}) = \\frac{1}{2n} \\sum_{i=1}^{n} \\left(y_i - \\hat{f}(\\mathbf{x}_i) \\right)^2 + \\lambda \\cdot \\sum_{j=1}^p |w_j|\n\\]\nDie Optimierung der LASSO Kostenfunktion hat allerdings einen gewichtigen Vorteil gegenüber Ridge, der nicht so offensichtlich ist: unwichtige Parameter werden bei LASSO auf 0 gesetzt, während Ridge die Parameter einfach kleiner macht, sie aber nie auf genau 0 setzt (ausser wenn \\(\\lambda \\to \\infty\\)). Das Modell nimmt also selbständig eine Selektion der wichtigen Variablen vor. Diese Eigenschaft macht das Modell auch gut interpretierbar, weil bei korrekter Anwendung von LASSE nur die relevanten Input-Variablen im Modell verbleiben.\n\n\n\n\n\n\nVorsichtWie funktioniert diese Variablenselektion bei LASSO? (optional)\n\n\n\n\n\nUm besser zu verstehen, warum LASSO eine automatische Variablenselektion vornimmt und die Modellparameter unwichtiger Input-Variablen auf Null setzt, muss das Optimierungsproblem in die Lagrange-Form (eingeschränkte Optimierung) gebracht werden:\n\\[\n\\text{Minimiere}\\quad \\frac{1}{2n} \\sum_{i=1}^{n} \\left(y_i - \\hat{f}(\\mathbf{x}_i) \\right)^2 \\text{unter der Bedingung}\\quad \\sum_{j=1}^p |w_j| \\leq s\n\\] \\(s\\) kann als Budget interpretiert werden (James u. a. 2021, pp. 241 - 245) und die Summe über die absoluten Werte der Modellparameter kann dieses Budget nicht übersteigen.\nJedes Budget \\(s\\) matcht einen Wert für \\(\\lambda\\), so dass dieselben Modellparameter resultieren. Oder in anderen Worten: die Problemformulierung hier ist identisch zu der obigen mit dem Unterschied, dass sie hier durch \\(s\\) charakterisiert ist und oben durch \\(\\lambda\\).\nDie Bedingung \\(\\sum_{j=1}^p |w_j| \\leq s\\) kann im Fall von zwei Input-Variablen mit den entsprechenden Modellparameter \\(w_1\\) und \\(w_2\\) gut visualisert werden:\n\n\n\n\n\nKonturplots der LASSO-Bedingung für drei verschiedene Budgets (1,2,3).\n\n\n\n\nDie drei abgebildeten Rauten entsprechend den Budgets \\(s=1,2,3\\). Jede Raute enthalt alle Kombinationen von Parameterwerten, welche zusammen genau das Budget ergeben. Wenn wir uns beispielsweise den Eckpunkt ganz oben in der äussersten Raute anschauen, dann haben wir dort die Parameterwerte \\(w_1=0\\) und \\(w_2=3\\); die Summe der absoluten Werte ist also genau 3.\nDie optimalen LASSO Modellparameter befinden sich nun an dem Punkt, wo die Konturlinien für den ersten Teil der Kostenfunktion (die Summe der quadrierten Differenzen, siehe auch Konturlinien oben für Kleinstquadratemethode) die Konturlinie der LASSO-Bedingung für ein gegebenes Budget \\(s\\) berühren. Ganz oft ist dieser Berührungspunkt in einer der Ecken. Wichtig: eine Ecke ist immer eine Parameterkombination, wo einer der Parameter den Wert 0 hat.\n\n\n\nDer Nachteil von LASSO im Vergleich zu Ridge ist, dass es keine analytische Lösung gibt. In der praktischen Arbeit stört uns dies allerdings nur wenig, da R oder Python Packages gut gerüstet sind, um das Optimierungsproblem für LASSO zu lösen.\nWichtig: wie bei Ridge müssen auch hier alle numerischen Input-Variablen zwingend standardisiert sein.",
    "crumbs": [
      "Klassisches Machine Learning",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Lineare Regression</span>"
    ]
  },
  {
    "objectID": "02_linreg.html#bias-variance-tradeoff",
    "href": "02_linreg.html#bias-variance-tradeoff",
    "title": "2  Lineare Regression",
    "section": "2.6 Bias-Variance Tradeoff",
    "text": "2.6 Bias-Variance Tradeoff\nWir haben oben bereits gesehen, dass der Hyperparameter \\(\\lambda\\) bestimmt, wie stark die Komplexität des Regressionsmodells eingeschränkt wird (oder in anderen Worten, die Parameter richtung Null geschrumpft werden).\nUm noch besser zu verstehen, warum es so wichtig ist, die Komplexität eines Modells korrekt einzustellen, wollen wir uns nun mit einem ganz wichtigen Konzept im Machine Learning beschäftigen, nämlich dem Bias-Variance Tradeoff. Dieses Konzept kann intuitiv für alle Bereiche des Supervised Learnings angewendet werden. Für das Regressionsproblem können wir diesen Tradeoff jedoch auch mathematisch herleiten (siehe auch James u. a. 2021) und genau das tun wir jetzt hier.\nStellen Sie sich vor, dass wir eine grosse Anzahl Trainingsdatensätze zur Verfügung haben und mit jedem dieser Datensätze versuchen wir den wahren funktionalen Zusammenhang \\(f(\\mathbf{x}_i)\\) möglichst gut mit \\(\\hat{f}(\\mathbf{x}_i)\\) zu schätzen. Für jeden Datensatz sieht das geschätzte Modell \\(\\hat{f}(\\mathbf{x}_i)\\) etwas anders aus (da es auf einem unterschiedlichen Datensatz trainiert wurde). Das geschätzte Modell, kurz \\(\\hat{f}\\), variiert also je nach Datensatz und ist dementsprechend eine Zufallsvariable.\nAusserdem treffen wir folgende Annahmen:\n\nVon oben wissen wir, dass \\(y_i = f(\\mathbf{x}_i) + \\epsilon\\) immer gilt.\nWir nehmen an, dass der Erwartungswert des nicht-lernbaren Teils \\(\\epsilon\\) Null ist, also \\(\\mathbb{E}[\\epsilon]=0\\).\nAusserdem gilt für die Varianz einer Zufallsvariable (in Kombination mit der zweiten Annahme, dass \\(\\mathbb{E}[\\epsilon]=0\\)): \\(\\text{Var}(\\epsilon) = \\mathbb{E}[\\epsilon^2] - \\mathbb{E}[\\epsilon]^2 = \\mathbb{E}[\\epsilon^2] - 0^2 = \\mathbb{E}[\\epsilon^2]\\).\n\nUm den Bias-Variance Tradeoff zu zeigen, leiten wir nun den Erwartungswert des quadrierten Fehlers für eine gegebene Testbeobachtung her, die wir als \\((y_0,\\mathbf{x}_0)\\) bezeichnen. Dies wäre der durchschnittliche quadrierte Fehler, den wir für diese Beobachtung kriegen würden, wenn wir mit jedem geschätzten Modell die Vorhersage für diese Testbeobachtung rechnen würden.\n\n\n\n\n\n\nVorsichtHerleitung (optional)\n\n\n\n\n\nIn einem ersten Schritt erweitern wir den quadrierten Fehler, indem wir einmal den wahren Funktionswert an der Stelle \\(\\mathbf{x}_0\\) abziehen und einmal hinzuzählen. Zusammen gibt das Null und verändert darum die rechte Seite der Gleichung nicht:\n\\[\\begin{align}\n\\mathbb{E}\\left[\\left(y_0 - \\hat{f}(\\mathbf{x}_0)\\right)^2\\right] &= \\mathbb{E}\\left[\\left(y_0 - f(\\mathbf{x}_0) + f(\\mathbf{x}_0) - \\hat{f}(\\mathbf{x}_0)\\right)^2\\right]\n\\end{align}\\]\nNun verwenden wir die bekannte polynomische Expansion \\((a+b)^2=a^2+2ab+b^2\\), aber hier behandeln wir \\(y_0 - f(\\mathbf{x}_0)\\) als \\(a\\) und \\(f(\\mathbf{x}_0) - \\hat{f}(\\mathbf{x}_0)\\) als \\(b\\). Dadurch kriegen wir folgende Gleichung:\n\\[\\begin{align}\n\\mathbb{E}\\left[\\left(y_0 - \\hat{f}(\\mathbf{x}_0)\\right)^2\\right] &= \\mathbb{E}\\biggl[\\left(y_0 - f(\\mathbf{x}_0)\\right)^2 \\\\\n&+ 2\\left(y_0 - f(\\mathbf{x}_0)\\right)(f(\\mathbf{x}_0) - \\hat{f}(\\mathbf{x}_0)) \\\\\n&+ (f(\\mathbf{x}_0) - \\hat{f}(\\mathbf{x}_0))^2\\biggr]\n\\end{align}\\]\nNun wissen wir aus obigen Annahmen, dass der Erwartungswert von \\(y_0\\) folgender ist: \\(\\mathbb{E}[y_0]=\\mathbb{E}[f(\\mathbf{x}_0) + \\epsilon]=f(\\mathbf{x}_0)\\). Dadurch entfällt der erste Teil des zweiten Terms, weil \\(\\mathbb{E}[\\left(y_0 - f(\\mathbf{x}_0)\\right)]=f(\\mathbf{x}_0) - f(\\mathbf{x}_0)=0\\). Dadurch lässt sich das Ganze massiv vereinfachen zu:\n\\[\\begin{align}\n\\mathbb{E}\\left[\\left(y_0 - \\hat{f}(\\mathbf{x}_0)\\right)^2\\right] &= \\mathbb{E}\\left[\\left(y_0 - f(\\mathbf{x}_0)\\right)^2\\right] + \\mathbb{E}\\left[(f(\\mathbf{x}_0) - \\hat{f}(\\mathbf{x}_0))^2\\right]\n\\end{align}\\]\nNun setzen wir im ersten Erwartungswert auf der rechten Seite anstelle von \\(y_0\\) den Term \\(f(\\mathbf{x}_0) + \\epsilon\\) ein und kriegen folgendes:\n\\[\\begin{align}\n\\mathbb{E}\\left[\\left(y_0 - \\hat{f}(\\mathbf{x}_0)\\right)^2\\right] &= \\mathbb{E}\\left[\\left(f(\\mathbf{x}_0) + \\epsilon - f(\\mathbf{x}_0)\\right)^2\\right] + \\mathbb{E}\\left[(f(\\mathbf{x}_0) - \\hat{f}(\\mathbf{x}_0))^2\\right] \\\\\n&= \\mathbb{E}\\left[\\epsilon^2\\right] + \\mathbb{E}\\left[(f(\\mathbf{x}_0) - \\hat{f}(\\mathbf{x}_0))^2\\right] \\\\\n&= \\text{Var}(\\epsilon) + \\mathbb{E}\\left[(f(\\mathbf{x}_0) - \\hat{f}(\\mathbf{x}_0))^2\\right]\n\\end{align}\\]\nDas ist schon mal ein erstes wichtiges Zwischenresultat. Der Erwartungswert des quadrierten Fehlers wird eine untere Grenze haben, die genau der Varianz des Fehlerterms, \\(\\text{Var}(\\epsilon)\\), entspricht. Diese untere Grenze des erwarteten Fehlers wird dann erreicht, wenn unser geschätztes Modell genau dem wahren entspricht und darum der zweite Term oben entfällt.\nNun wollen wir diesen zweiten Term oben noch etwas weiter aufspalten. Dazu brauchen wir wiederum den Trick, den wir oben bereits angewendet haben. Wir ziehen den Erwartungswert des geschätzten Modells \\(\\mathbb{E}\\left[\\hat{f}(\\mathbf{x}_0)\\right]\\) einmal ab und fügen ihn einmal hinzu:\n\\[\\begin{align}\n\\mathbb{E}\\left[(f(\\mathbf{x}_0) - \\hat{f}(\\mathbf{x}_0))^2\\right] &= \\mathbb{E}\\left[\\left(f(\\mathbf{x}_0) - \\mathbb{E}\\left[\\hat{f}(\\mathbf{x}_0)\\right] + \\mathbb{E}\\left[\\hat{f}(\\mathbf{x}_0)\\right] - \\hat{f}(\\mathbf{x}_0)\\right)^2\\right] \\\\\n&= \\mathbb{E}\\left[\\left(f(\\mathbf{x}_0) - \\mathbb{E}\\left[\\hat{f}(\\mathbf{x}_0)\\right] - \\left(\\hat{f}(\\mathbf{x}_0) - \\mathbb{E}\\left[\\hat{f}(\\mathbf{x}_0)\\right]\\right)\\right)^2\\right]\n\\end{align}\\]\nÄhnlich wie weiter oben können wir diese Gleichung mit einer polynomischen Expansion wie folgt umschreiben:\n\\[\\begin{align}\n\\mathbb{E}\\left[(f(\\mathbf{x}_0) - \\hat{f}(\\mathbf{x}_0))^2\\right] &= \\mathbb{E}\\biggl[\\left(f(\\mathbf{x}_0) - \\mathbb{E}\\left[\\hat{f}(\\mathbf{x}_0)\\right]\\right)^2 \\\\\n&- 2\\left(f(\\mathbf{x}_0) - \\mathbb{E}\\left[\\hat{f}(\\mathbf{x}_0)\\right]\\right)\\left(\\hat{f}(\\mathbf{x}_0) - \\mathbb{E}\\left[\\hat{f}(\\mathbf{x}_0)\\right]\\right) \\\\\n&+ \\left(\\hat{f}(\\mathbf{x}_0) - \\mathbb{E}\\left[\\hat{f}(\\mathbf{x}_0)\\right]\\right)^2\\biggr]\n\\end{align}\\]\nAuch hier entfällt der mittlere Term, wenn wir den Erwartungswert in die Klammern reinnehmen, weil der zweite Teil \\(\\left(\\mathbb{E}\\left[\\hat{f}(\\mathbf{x}_0)\\right] - \\mathbb{E}\\left[\\hat{f}(\\mathbf{x}_0)\\right]\\right)=0\\) ist.\nWas übrig bleibt ist folgendes:\n\\[\\begin{align}\n\\mathbb{E}\\left[(f(\\mathbf{x}_0) - \\hat{f}(\\mathbf{x}_0))^2\\right] &= \\mathbb{E}\\left[\\left(f(\\mathbf{x}_0) - \\mathbb{E}\\left[\\hat{f}(\\mathbf{x}_0)\\right]\\right)^2\\right] + \\mathbb{E}\\left[\\left(\\hat{f}(\\mathbf{x}_0) - \\mathbb{E}\\left[\\hat{f}(\\mathbf{x}_0)\\right]\\right)^2\\right] \\\\\n&= \\left(f(\\mathbf{x}_0) - \\mathbb{E}\\left[\\hat{f}(\\mathbf{x}_0)\\right]\\right)^2 + \\mathbb{E}\\left[\\left(\\hat{f}(\\mathbf{x}_0) - \\mathbb{E}\\left[\\hat{f}(\\mathbf{x}_0)\\right]\\right)^2\\right]\n\\end{align}\\]\nSchauen wir uns kurz die beiden Komponenten auf der rechten Seite etwas genauer an:\n\n\\(\\left(f(\\mathbf{x}_0) - \\mathbb{E}\\left[\\hat{f}(\\mathbf{x}_0)\\right]\\right)^2\\) ist der quadrierte Bias und misst die systematische Abweichung unseres geschätzten Modells \\(\\hat{f}\\) vom wahren unbekannten Modell \\(f\\). Je kleiner der Bias, desto tiefer der erwartete quadrierte Fehler. Wir können diesen Term der Einfachheit halber mit \\(\\left[\\text{Bias}\\left(\\hat{f}(\\mathbf{x}_0)\\right)\\right]^2\\) bezeichnen.\n\\(\\mathbb{E}\\left[\\left(\\hat{f}(\\mathbf{x}_0) - \\mathbb{E}\\left[\\hat{f}(\\mathbf{x}_0)\\right]\\right)^2\\right]\\) ist nichts anderes als die Varianz unseres geschätzten Modells \\(\\hat{f}\\). Sie misst, wie stark sich \\(\\hat{f}\\) im Schnitt verändert, wenn wir einen anderen Datensatz für das Training verwenden. Ein Modell mit hoher Varianz passt sich jeweils sehr stark an die Daten an. Je kleiner diese Varianz, desto tiefer der erwartete quadrierte Fehler. Wir bezeichnen diesen Term der Einfachheit halber als \\(\\text{Var}\\left(\\hat{f}(\\mathbf{x}_0)\\right)\\).\n\nNun sind wir endlich am Ziel angelangt und können den erwarteten quadrierten Fehler für die Beobachtung \\((y_0,\\mathbf{x}_0)\\) wie folgt aufschreiben:\n\\[\n\\mathbb{E}\\left[\\left(y_0 - \\hat{f}(\\mathbf{x}_0)\\right)^2\\right] = \\text{Var}(\\epsilon) + \\left[\\text{Bias}\\left(\\hat{f}(\\mathbf{x}_0)\\right)\\right]^2 + \\text{Var}\\left(\\hat{f}(\\mathbf{x}_0)\\right)\n\\]\n\n\n\nDer erwartete quadrierte Fehler für die Beobachtung \\((y_0,\\mathbf{x}_0)\\) kann wie folgt beschrieben werden:\n\\[\n\\mathbb{E}\\left[\\left(y_0 - \\hat{f}(\\mathbf{x}_0)\\right)^2\\right] = \\text{Var}(\\epsilon) + \\left[\\text{Bias}\\left(\\hat{f}(\\mathbf{x}_0)\\right)\\right]^2 + \\text{Var}\\left(\\hat{f}(\\mathbf{x}_0)\\right)\n\\]\n\nEin Modell mit viel Bias, also \\(\\text{Bias}\\left(\\hat{f}(\\mathbf{x}_0)\\right)\\), führt zu einer schlechten Vorhersagequalität (auf Trainings- und Testdaten), weil das Modell zu rigide ist, um den wahren Zusammenhang zwischen der Output-Variable und den Input-Variablen zu modellieren. Beispiel: wir verwenden ein einfaches lineares Regressionsmodell, um einen stark nicht-linearen Zusammenhang zwischen \\(y_i\\) und \\(\\mathbf{x}_i\\) zu modellieren. Im Fall von Modellen mit viel Bias spricht man auch von Underfitting.\nEin Modell mit viel Varianz führt zu einer hervorragenden Vorhersagequalität auf den Trainingsdaten, aber zu einer sehr schlechten Vorhersagequalität auf den Testdaten. Das Problem hier ist, dass das Model zu flexibel ist gemessen an der Grösse des Trainingsdatensatzes. Das Modell passt sich so zu stark an die Trainingsdaten an und modelliert auch sogenanntes Noise, also \\(\\epsilon\\) (und nicht nur das Signal in den Daten). Beispiel: wir modellieren ein neuronales Netzwerk, haben aber nur einen Trainingsdatensatz von einigen hundert Beobachtungen. Im Fall von Modellen mit viel Varianz spricht man auch von Overfitting.\nDer dritte Term, \\(\\text{Var}(\\epsilon)\\), ist die Varianz des Fehlerterms. Es ist der nicht-reduzierbare Teil des erwartbaren Vorhersagefehlers, d.h., wir erwarten selbst wenn wir das bestmögliche Modell gefunden haben einen gewissen Fehler.\n\nWarum spricht man von einem Tradeoff? Flexiblere Modelle haben oft einen kleinen Bias, aber hohe Varianz, während unflexible Modelle oft eine kleine Varianz, aber einen hohen Bias haben. Es existiert also ein Tradeoff zwischen Bias und Varianz und wir wollen beim Modellieren und vor allem beim Hyperparameter Tuning (zum Beispiel \\(\\lambda\\)) den optimalen Tradeoff finden.\n\nRegularisierte Regression revisited\nDer Hyperparameter \\(\\lambda\\) spielt bei der regularisierten Regression eine zentrale Rolle für den Tradeoff zwischen Bias und Variance. Ein zu tiefer Wert für \\(\\lambda\\) kann zu einem zu flexiblen Modell mit viel Varianz führen. Ein zu hoher Wert für \\(\\lambda\\) führt zu einem zu rigiden Modell mit viel Bias.\nIm folgenden Beispiel haben wir \\(n = 50\\) Beobachtungen. Die Daten wurden durch folgenden Prozess generiert:\n\\[\ny_i = 2 + 1 \\cdot x_{i,1} + \\epsilon_i\n\\] wobei \\(\\epsilon_i \\sim N(0, 0.2)\\). Das wahre Modell ist dementsprechend \\(f(\\mathbf{x}_i) = 2 + 1 \\cdot x_{i,1}\\).\nDer Datensatz enthält aber 49 weitere Prädiktoren \\(x_{i,2}, x_{i,3}, \\dots, x_{i,50}\\), welche nicht mit der Output-Variable \\(y_i\\) korreliert sind. Als Analyst:in wissen Sie das jedoch nicht. Sie sehen lediglich die 50 Input-Variablen und die Output-Variable.\nFolgende Abbildung zeigt die Resultate von vier LASSO Modellen mit unterschiedlichen Werten für \\(\\lambda\\).\n\n\n\n\n\nResultate eines LASSO Modells für vier verschiedene Werte des Hyperparameters. Links: die trainierten Parameterwerte für die Konstante sowie die 50 Input-Variablen. Rechts: Vorhersagegüte (gemessen als RMSE) auf Trainings- und Testdaten. Für die Testdaten wurden weitere 50 Beobachtungen generiert, die aber nicht für das Training verwendet wurden.\n\n\n\n\n\n\nFrage\nWelches der vier abgebildeten Modelle mit entsprechendem Wert für \\(\\lambda\\) ist optimal?\n\n\n\n\n\n\nTippLösung\n\n\n\n\n\nDas dritte Modell mit \\(\\lambda = 0.1\\) ist optimal. Wir sehen, dass in diesem Fall nur die Gewichte \\(w_0 \\approx 2\\) und \\(w_1 \\approx 1\\) nicht Null sind. Ausserdem sind die beiden RMSE Werte auf Trainings- und Testdaten ähnlich und auf tiefem Niveau.\nDas erste Modell (\\(\\lambda = 0\\)) entspricht der Kleinstquadratemethode und ist ein gutes Beispiel für Overfitting. Das Modell verwendet alle 50 Input-Variablen und kann so den RMSE auf den Trainingsdaten fast auf 0 reduzieren. Der Testdaten-RMSE ist dann aber vergleichsweise hoch - ein typisches Zeichen von Overfitting.\nDer vierte Modell (\\(\\lambda = 10\\)) ist ein perfektes Beispiel von Underfitting. Der Regularisierungsterm \\(\\lambda\\) ist so gross, dass nur noch ein Modell mit einer Konstante \\(w_0 \\approx 2\\) geschätzt wurde. Entsprechend sind sowohl der RMSE auf den Trainingsdaten als auch der RMSE auf den Testdaten hoch - ein typisches Zeichen von Underfitting.\nDas zweite Modell ist nicht schlecht, aber zeigt immer noch leichte Anzeichen von Overfitting.\n\n\n\nWichtig:\n\nIndem wir den Hyperparameter via Resampling (z.B. K-Fold Cross Validation, später mehr dazu) optimieren, wählen wir automatisch ein Modell mit einem guten Tradeoff zwischen Bias und Varianz!\nMit grossen Datensätzen ist das Problem des Overfittings weniger dramatisch. Haben wir genügend Trainingsdaten, dann können selbst flexible Modelle nicht zu stark overfitten. Die Anzahl Trainingsdaten hat also einen regulierenden Einfluss.\n\nEine letzte Überlegung bezüglich Modellselektion geht folgendermassen: wenn wir mehrere Modelle haben, die ähnlich gut performen, dann wählen wir das einfachste (kleinste) oder am wenigsten komplexe Modell. Man nennt dies Occam’s Razor. William of Occam war ein Englischer Mönch und hat dieses Prinzip in einem anderen Kontext erstmals formuliert.",
    "crumbs": [
      "Klassisches Machine Learning",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Lineare Regression</span>"
    ]
  },
  {
    "objectID": "02_linreg.html#polynomische-regression",
    "href": "02_linreg.html#polynomische-regression",
    "title": "2  Lineare Regression",
    "section": "2.7 Polynomische Regression",
    "text": "2.7 Polynomische Regression\nWir machen hier nun einen kurzen Abstecher und lernen die polynomische Regression kennen, denn diese eignet sich auch sehr gut, um den Bias-Variance Tradeoff zu illustrieren.\nDas polynomische Regressionsmodell sieht im Fall von einer Input-Variable \\(x_i\\) folgendermassen aus:\n\\[\ny_i = w_0 + w_1 \\cdot x_i^1 + w_2 \\cdot x_i^2 + w_3 \\cdot x_i^3 + \\dotsb + w_M \\cdot x_i^M + \\epsilon_i\n\\]\nEs handelt sich also um ein Regressionsmodell wie wir es kennen gelernt haben, einfach mit den Polynomen von \\(x_i\\) bis zum \\(M\\)-ten Grad als Input-Variablen.\nMit einem Datensatz der Grösse \\(n\\), kann ein polynomisches Regressionsmodell mit Grad \\(M = n−1\\) die Daten perfekt abbilden. Das Modell hat in diesem Fall so viele Freiheitsgrade wie der Trainingsdatensatz Beobachtungen hat. Dabei handelt es sich um ein extremes Beispiel von Overfitting.\nWir sehen in untenstehender Abbildung drei Fälle einer polynomischen Regression. Die schwarze Kurve zeigt das wahre Modell, von dem die blauen Datenpunkte unter Hinzufügen von etwas Noise generiert wurden. Die braune Kurve zeigt das jeweils geschätzte Modell. Rechts sehen Sie ähnlich wie oben jeweils den RMSE auf Trainings- und auf Testdaten.\nFolgende Punkte gilt es festzuhalten:\n\nDas erste Modell ist eine polynomische Regression mit Grad \\(M=0\\), in der nur die Konstante \\(w_0\\) in das Modell einfliesst. Ein klarer Fall von Underfitting.\nDas zweite Modell ist eine polynomische Regression mit Grad \\(M=9\\), das mit \\(n=10\\) Beobachtungen trainiert wird - das bereits angesprochene Beispiel von extremem Overfitting.\nBeim dritten Modell zeigt sich der regulierende Effekt von mehr Trainingsdaten. Das komplexe Modell mit \\(M=9\\) führt im Fall von \\(n=100\\) Trainingsbeobachtungen zu einem sehr guten Fit.\n\n\n\n\n\n\nPolynomische Regression für drei verschiedene Fälle mit unterschiedlichen polynomischen Graden und Anzahl Trainingsbeobachtungen. Rechts: Vorhersagegüte (gemessen als RMSE) auf Trainings- und Testdaten. Für die Testdaten wurden weitere n Beobachtungen generiert, die aber nicht für das Training verwendet wurden.\n\n\n\n\nWichtig: das polynomische Regressionsmodell ist immer noch linear in den Parametern, es handelt sich also immer noch um ein lineares Modell. Sie sehen aber an obigen Modellkurven, dass dieses “lineare” Modell sehr wohl in der Lage ist, nicht-lineare Zusammenhänge zwischen \\(x\\) und \\(y\\) zu fitten!",
    "crumbs": [
      "Klassisches Machine Learning",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Lineare Regression</span>"
    ]
  },
  {
    "objectID": "02_linreg.html#lineare-regression-in-r",
    "href": "02_linreg.html#lineare-regression-in-r",
    "title": "2  Lineare Regression",
    "section": "2.8 Lineare Regression in R",
    "text": "2.8 Lineare Regression in R\n\n2.8.1 Base R\nIn Base R lassen sich Regressionsmodelle einfach mit der lm() Funktion (lm steht für linear model) rechnen.\n\n# Datenpunkte\nx &lt;- c(-4.1, -0.5, 1.4, 4.4)\ny &lt;- c(3.5, 1.95, -2.5, -2.05)\n\n# Dataframe\ndf &lt;- data.frame(x = x, y = y)\n\n# Modellrechnung (Kleinsquadrateschätzer)\nmod &lt;- lm(y ~ x, data = df)\n\n# Modelloutput\nsummary(mod)\n\n\nCall:\nlm(formula = y ~ x, data = df)\n\nResiduals:\n       1        2        3        4 \n 0.02129  1.13342 -1.91157  0.75686 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)   0.4468     0.8340   0.536    0.646\nx            -0.7395     0.2692  -2.747    0.111\n\nResidual standard error: 1.66 on 2 degrees of freedom\nMultiple R-squared:  0.7904,    Adjusted R-squared:  0.6857 \nF-statistic: 7.544 on 1 and 2 DF,  p-value: 0.1109\n\n\nDer obige R Output ist der klassische Regressionsoutput der lm() Funktion. In der Spalte Estimate sehen wir insbesondere die geschätzten (trainierten) Modellparameter.\nWir können unser geschätztes Modell nun wie folgt verwenden, um Vorhersagen für zwei neue Input-Variablenwerte (2.5 und 5.1) zu machen.\n\n# Modellvorhersagen\nyp &lt;- predict(mod, newdata = data.frame(x = c(2.5, 5.1)))\nyp\n\n        1         2 \n-1.401854 -3.324500 \n\n\n\n\n2.8.2 tidymodels + glmnet\nFür regularisierte Regressionsmodelle eignet sich der tidymodels Framework in Kombination mit glmnet (letzteres ist die Engine für regularisierte Modelle aller Art). Wir laden als erstes die beiden Packages. Beim ersten Mal müssen diese Packages mit install.packages(c(\"tidymodels\", \"glmnet\")) installiert werden.\n\nlibrary(tidymodels)\nlibrary(glmnet)\n\nWir generieren hier dieselben Daten wie in einer der Demos oben, wo wir die regularisierte Regression demonstriert haben. Die Daten werden wie oben nach folgendem Modell generiert:\n\\[\ny_i = 2 + 1 \\cdot x_{i,1} + \\epsilon_i\n\\] Der folgende Code-Block generiert die Daten:\n\n# Seed für Reproduzierbarkeit\nset.seed(123)\n\n# Wir definieren die Anzahl Beobachtungen, die Anzahl Input-Var.\n# und die Standardabweichung des Fehlerterms.\nn &lt;- 50\np &lt;- 50\nsd &lt;- 0.2\n\n# Nun simulieren wir die Input-Variablenwerte aus einer Normalverteilung.\nXtrain &lt;- matrix(rnorm(n * p), nrow = n)\n\n# Generierung der y-Werte mit normalverteiltem Noise.\nytrain &lt;- 2 + Xtrain[, 1] + rnorm(n, 0, sd)\n\n# Wir fassen die Input-Variablen und den Output zu einem Dataframe zusammen.\ntrain &lt;- as.data.frame(Xtrain)\ntrain$y &lt;- ytrain\n\nIm folgenden Code verwenden wir tidymodels, um ein lineares Regressionsmodell mit linear_reg() zu initialisieren. In tidymodels heisst der Hyperparameter \\(\\lambda\\) penalty und mit mixture = 1 definieren wir, dass ein LASSO Modell gerechnet werden soll (mixture = 0 würde einem Ridge Modell entsprechen).\n\n# Modellspezifikation für lineares Modell mit Regularisierung\nlm_mod &lt;- \n  linear_reg(penalty = 0.1, mixture = 1) |&gt; \n  set_engine(\"glmnet\")\n\nNun fitten wir das Modell mit fit(). Mit formula = y ~ . legen wir fest, dass y die Outputvariable ist und dass alle anderen Variablen im Dataframe train als Input-Variablen verwendet werden sollen.\n\n# Modelltraining\nlm_fit &lt;-\n  lm_mod |&gt; \n  fit(formula = y ~ ., data = train)\n\nNun können wir uns noch die trainierten Modellparameter (in der Spalte estimate) anschauen.\n\n# Parameter des Modells\ntidy(lm_fit) %&gt;% \n  print(n = 51)\n\n# A tibble: 51 × 3\n   term        estimate penalty\n   &lt;chr&gt;          &lt;dbl&gt;   &lt;dbl&gt;\n 1 (Intercept)    2.00      0.1\n 2 V1             0.887     0.1\n 3 V2             0         0.1\n 4 V3             0         0.1\n 5 V4             0         0.1\n 6 V5             0         0.1\n 7 V6             0         0.1\n 8 V7             0         0.1\n 9 V8             0         0.1\n10 V9             0         0.1\n11 V10            0         0.1\n12 V11            0         0.1\n13 V12            0         0.1\n14 V13            0         0.1\n15 V14            0         0.1\n16 V15            0         0.1\n17 V16            0         0.1\n18 V17            0         0.1\n19 V18            0         0.1\n20 V19            0         0.1\n21 V20            0         0.1\n22 V21            0         0.1\n23 V22            0         0.1\n24 V23            0         0.1\n25 V24            0         0.1\n26 V25            0         0.1\n27 V26            0         0.1\n28 V27            0         0.1\n29 V28            0         0.1\n30 V29            0         0.1\n31 V30            0         0.1\n32 V31            0         0.1\n33 V32            0         0.1\n34 V33            0         0.1\n35 V34            0         0.1\n36 V35            0         0.1\n37 V36            0         0.1\n38 V37            0         0.1\n39 V38            0         0.1\n40 V39            0         0.1\n41 V40            0         0.1\n42 V41            0         0.1\n43 V42            0         0.1\n44 V43            0         0.1\n45 V44            0         0.1\n46 V45            0         0.1\n47 V46            0         0.1\n48 V47            0         0.1\n49 V48            0         0.1\n50 V49            0         0.1\n51 V50            0         0.1\n\n\nVorschlag: Kopieren Sie die Codezeilen in ein lokales Skript und probieren Sie andere Werte für den Hyperparameter \\(\\lambda\\) (penalty) aus.\n\n\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, und Robert Tibshirani. 2021. An Introduction to Statistical Learning: with Applications in R. 2. Aufl. Springer. https://www.statlearning.com/.",
    "crumbs": [
      "Klassisches Machine Learning",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Lineare Regression</span>"
    ]
  },
  {
    "objectID": "02_linreg.html#footnotes",
    "href": "02_linreg.html#footnotes",
    "title": "2  Lineare Regression",
    "section": "",
    "text": "\\(\\epsilon = y_i - f(\\mathbf{x}_i)\\)↩︎\nSo müssen wir die Konstante \\(w_0\\) nicht separat aufschreiben.↩︎\nDas Quadrieren führt dazu, dass grosse Differenzen die gesamte Summe der quadrierten Fehler dominieren.↩︎\nFalls Sie den optionalen Teil “Kleinsquadratemethode in Matrixform” angeschaut haben: in diesem Fall ist die Matrix \\(\\mathbf{X}'\\mathbf{X}\\) nicht invertierbar.↩︎\nFormel für die Standardisierung: \\(\\frac{y_i-\\bar{y}}{s_y}\\)↩︎\nLASSO ist die Abkürzung für least absolute shrinkage and selection operator↩︎",
    "crumbs": [
      "Klassisches Machine Learning",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Lineare Regression</span>"
    ]
  },
  {
    "objectID": "03_linclass.html",
    "href": "03_linclass.html",
    "title": "3  Lineare Klassifikation",
    "section": "",
    "text": "3.1 Logistische Regression\nComing soon.",
    "crumbs": [
      "Klassisches Machine Learning",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Lineare Klassifikation</span>"
    ]
  },
  {
    "objectID": "03_linclass.html#naive-bayes",
    "href": "03_linclass.html#naive-bayes",
    "title": "3  Lineare Klassifikation",
    "section": "3.2 Naive Bayes",
    "text": "3.2 Naive Bayes\nComing soon.",
    "crumbs": [
      "Klassisches Machine Learning",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Lineare Klassifikation</span>"
    ]
  },
  {
    "objectID": "03_linclass.html#k-nearest-neighbors",
    "href": "03_linclass.html#k-nearest-neighbors",
    "title": "3  Lineare Klassifikation",
    "section": "3.3 K-Nearest Neighbors",
    "text": "3.3 K-Nearest Neighbors\n\n\n\nNicht-parametrische Modelle wiederum sind Modelle, welche nicht (oder zumindest nicht explizit) durch Parameter charakterisiert sind. Am besten schauen wir uns gleich ein einfaches nicht-parametrisches Modell an, nämlich das K-Nearest-Neighbors (KNN) Modell. Stellen Sie sich vor, Sie haben einen Datensatz mit 55 Produkten aus Ihrem Sortiment. Sie haben jedes dieser 55 Produkte auf Instagram und auf Tiktok durch Influencer*innen bewerben lassen. Für jedes der 55 Produkte hatten Sie ein Werbebudget für Instagram (\\(x_{i1}\\)) und ein Werbebudget für Tiktok (\\(x_{i2}\\)). Am Ende des Geschäftsjahrs haben Sie für jedes der 55 Produkte bestimmt, ob die Absatzziele erreicht wurden oder nicht (Output \\(y_i\\)). Die erfolgreichen Produkte (= Absatzziel erreicht) sind in untenstehender App als blaue Punkte eingezeichnet. Die roten Dreiecke repräsentieren die nicht-erfolgreichen Produkte. Sie sehen, dass erfolgreiche Produkte tendenziell höhere Instagram und Tiktok Werbebudgets aufwiesen als nicht-erfolgreiche Produkte. Sie möchten nun ein Modell schätzen, dass die Produkte automatisch klassifizieren kann. Dazu verwenden Sie das KNN Modell, das die \\(K\\) nächsten Nachbarn unter den 55 gegebenen Produkten sucht und dann die häufigste Beobachtung unter den \\(K\\) nächsten Nachbarn vorhersagt. In anderen Worten: wir suchen die \\(K\\) ähnlichsten Beobachtungen und nutzen diese, um eine Vorhersage zu machen.\nSelbstverständlich spielt der konkrete Wert von \\(K\\) hier eine grosse Rolle - sollen wir nur \\(K=1\\) Nachbarn berücksichtigen? Oder \\(K=10\\) Nachbarn? Die erste Abbildung in der App zeigt nicht nur die 55 Datenpunkte, sondern auch die Entscheidungsgrenze (in schwarz). Untersuchen Sie kurz, wie sich diese Entscheidungsgrenze verändert, wenn Sie \\(K\\) erhöhen oder reduzieren.\nAusserdem können Sie in der ersten Abbildung auch den schwarzen Punkt mit der Maus setzen, wodurch Ihnen die \\(K\\) nächsten Punkte des schwarzen Punkts angezeigt werden.\nDie zweite Abbildung zeigt die Entscheidungsregionen mit unterschiedlicher Intensität je nachdem wie sicher sich das Modell ist. In einer Region, in der alle \\(K\\) Nachbarn nicht-erfolgreiche Produkte sind, sind wir uns eher sicher bezüglich der Vorhersage als in einer Region, in der die Anteile zwischen erfolgreichen und nicht-erfolgreichen Produkten ausgeglichen sind.\n\n\n\n\nUm die \\(K\\) nächsten Nachbarn zu finden, müssen wir die Distanzen zwischen Punkten rechnen können. Dazu verwenden wir die Euklidische Distanz, welche wir in Kapitel @ref(basics) kennen lernen werden.\nDas KNN Modell ist ein sehr einfaches ML Modell, welches in der Praxis allerdings nicht allzu häufig angewendet wird. Warum nicht? Weil es am sogenannten Fluch der Dimensionalität (engl. Curse of Dimensionality) leidet. Doch was bedeutet das? Je mehr Input-Variablen wir haben, desto weiter entfernt sind Datenpunkte voneinander (das ist etwas, das man sich nur schwer vorstellen kann, aber Sie können es mir für den Moment einfach mal glauben). Das KNN beruht auf der Grundidee, dass wir \\(K\\) nahe, ähnliche Beobachtungen für die Vorhersage verwenden. Wenn diese \\(K\\) nahen Beobachtungen im hochdimensionalen Raum (= viele Input-Variablen) nicht mehr nahe sind, dann funktioniert auch das Modell nicht mehr gut.\n\nFragen\nStellen Sie sich vor, Sie haben folgendes Klassifikationsproblem, das Sie mit KNN lösen wollen. Welche Kategorie prognostiziert ein KNN Modell für den Punkt \\(x\\) in der unten stehenden Abbildung?\n\nBlauer Kreis.\nBeide Klassen sind gleich wahrscheinlich.\nRotes Kreuz.\n\n\n\n\n\n\n\nTippLösung\n\n\n\n\n\nEs hat drei rote Kreuze und zwei blaue Kreise in der Nachbarschaft. Die roten Kreuze sind darum in der Mehrheit, weshalb Antwort c korrekt ist.\n\n\n\n\n\n\n\n\n\nAbbildung 3.1: KNN Modell für binäres Klassifikationsproblem\n\n\n\nWas ist der Wert für \\(K\\) für das KNN Modell in der oben stehenden Abbildung?\n\n5\n2\n3\n10\n\n\n\n\n\n\n\nTippLösung\n\n\n\n\n\nDie Nachbarschaft, dargestellt durch den Kreis, enthält 5 Beobachtungen. Deshalb ist Antwort a korrekt.\n\n\n\nStellen Sie sich vor, Sie haben folgendes Regressionsproblem, das Sie mit KNN lösen wollen. Was ist die Vorhersage für den Punkt \\(x\\) für das KNN-Regressionsmodell in der unten stehenden Abbildung? Die Zahlen neben den Datenpunkten stellen die entsprechenden \\(y_i\\)-Werte dar.\n\n4\n20\n5\n\n\n\n\n\n\n\nTippLösung\n\n\n\n\n\nDer Durchschnitt über die 5 \\(y_i\\)-Werte in der Nachbarschaft beträgt 4, weshalb Antwort a korrekt ist.\n\n\n\n\n\n\n\n\n\nAbbildung 3.2: KNN Modell für Regressionsproblem",
    "crumbs": [
      "Klassisches Machine Learning",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Lineare Klassifikation</span>"
    ]
  },
  {
    "objectID": "04_pipeline.html",
    "href": "04_pipeline.html",
    "title": "4  ML Pipeline",
    "section": "",
    "text": "Abbildung 4.1 zeigt, wie eine typische ML-Pipeline aussieht.1\nSie starten typischerweise mit einem Problem oder einer Herausforderung. Ihr ganzes Projekt sollte darauf ausgelegt sein, dieses Problem zu lösen. Es ist grundsätzlich nicht ratsam, auf Biegen und Brechen eine ML Lösung zu implementieren, wenn kein klar definiertes Problem vorliegt. Nehmen Sie sich also zu Beginn eines Projekts Zeit, das Problem grundlegend zu definieren. Sprechen Sie auch mit den entsprechenden Fachexpert*innen im Unternehmen, um genau zu verstehen, was verbessert oder effizienter gemacht werden soll und was die technischen oder ökonomischen Einschränkungen sind.\nSobald das Problemverständnis vorhanden ist, beginnen Sie, sich mit den verfügbaren Daten zu befassen. Auch hier müssen Sie sich wahrscheinlich mit den entsprechenden Expert*innen im Unternehmen (z.B. Datenbankadministrator*innen) austauschen. Es geht hier unter anderem darum abzuklären, welche Daten verfügbar sind, in welchem Format die Daten vorhanden sind wie die Datenqualität ist.\nDanach beginnen Sie mit den Datenarbeiten. Häufig wird dieser Schritt Preprocessing oder Data Cleaning genannt. Oft verschlingt dieser Arbeitsschritt sehr viel Zeit und es ist nicht unüblich, dass 80% der Projektzeit hier aufgewendet werden. Es ist auch völlig normal, wenn Sie von diesem Schritt zurück zur Problemdefinition gehen und sie verfeinern oder anpassen müssen oder zum Beispiel nochmals Fragen mit den Datenbankexpert*innen klären müssen, weil Ihr Datenverständnis noch nicht vollständig ist.\nNachdem die Daten vorbereitet wurden, gehen Sie typischerweise zu einer explorativen Analyse der Daten über. Das heisst, Sie visualisieren die vorhandenen Variablen univariat (d.h. jede Variable einzeln) oder multivariat (d.h. zwei oder mehr Variablen zusammen). Ein Beispiel einer univariaten Visualisierung ist ein Histogramm einer quantitativen Variable (z.B. Quartalsumsätze). Ein Beispiel einer multivariaten Visualisierung ist ein Streudiagramm zweier quantitativer Variablen (z.B. Quartalsumsätze und Wechselkurse). Auch hier ist es üblich, dass Sie einen Schritt zurück gehen und weitere Datenbereinigungen vornehmen müssen.\nNach der explorativen Analyse der Daten sollten Sie eine erste Idee von den wichtigsten Zusammenhängen in den Daten haben. Basierend darauf können Sie Ihr erstes Modell wählen und trainieren und mit der eigentlichen Analyse bzw. der Lösung des Problems beginnen.\nEiner der wichtigsten Schritte ist die saubere und gründliche Evaluation Ihrer Modelle. Dieser Schritt dient einerseits dazu das beste Modell auszuwählen und andererseits dazu die Qualität Ihrer Lösung bzw. Ihres Modells abzuschätzen. Mit diesem zweiten Schritt wollen Sie nämlich bereits während der Projektphase einschätzen können, wie gut Ihr Modell das gegebene Problem löst oder einen bestehenden Betriebsprozess verbessert oder effizienter macht. Die beiden Schritte Analyse und Evaluation werden typischerweise ein paar Mal iteriert, bis Sie das beste Modell gefunden haben.\nAm Schluss geht es darum, dass Sie Ihr Wissen und Ihre Erkenntnisse an die relevanten Fachexpert*innen weitergeben (Wissenstransfer) und Ihr finales Modell in einer produktiven Umgebung implementieren (oft Deployment genannt). Zum Beispiel können Sie Ihr Modell in einer mobilen App einbetten oder als REST API Service zur Verfügung stellen.",
    "crumbs": [
      "Klassisches Machine Learning",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ML Pipeline</span>"
    ]
  },
  {
    "objectID": "04_pipeline.html#footnotes",
    "href": "04_pipeline.html#footnotes",
    "title": "4  ML Pipeline",
    "section": "",
    "text": "Icons stammen von https://thenounproject.com/.↩︎",
    "crumbs": [
      "Klassisches Machine Learning",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ML Pipeline</span>"
    ]
  },
  {
    "objectID": "05_tree.html",
    "href": "05_tree.html",
    "title": "5  Entscheidungsbäume",
    "section": "",
    "text": "Coming soon.",
    "crumbs": [
      "Klassisches Machine Learning",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Entscheidungsbäume</span>"
    ]
  },
  {
    "objectID": "06_ensemble.html",
    "href": "06_ensemble.html",
    "title": "6  Ensembles",
    "section": "",
    "text": "Coming soon.",
    "crumbs": [
      "Klassisches Machine Learning",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Ensembles</span>"
    ]
  },
  {
    "objectID": "07_svm.html",
    "href": "07_svm.html",
    "title": "7  Support Vector Machines",
    "section": "",
    "text": "Coming soon.",
    "crumbs": [
      "Klassisches Machine Learning",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Support Vector Machines</span>"
    ]
  },
  {
    "objectID": "deep.html",
    "href": "deep.html",
    "title": "Deep Learning",
    "section": "",
    "text": "In diesem zweiten Teil des Buchs befassen wir uns nun mit den modernen Entwicklungen im Machine Learning, nämlich dem Deep Learning.\nWir bauen hierfür jedoch auf dem ersten Teil auf. Es macht also Sinn, die Kapitel in diesem Buch wirklich in der von mir vorgeschlagenen Reihenfolge zu lesen.",
    "crumbs": [
      "Deep Learning"
    ]
  },
  {
    "objectID": "08_ann.html",
    "href": "08_ann.html",
    "title": "8  Artificial Neural Networks",
    "section": "",
    "text": "Coming soon.",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Artificial Neural Networks</span>"
    ]
  },
  {
    "objectID": "09_cnn.html",
    "href": "09_cnn.html",
    "title": "9  Convolutional Neural Networks",
    "section": "",
    "text": "Coming soon.",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Convolutional Neural Networks</span>"
    ]
  },
  {
    "objectID": "10_rnn.html",
    "href": "10_rnn.html",
    "title": "10  Recurrent Neural Networks",
    "section": "",
    "text": "Coming soon.",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Recurrent Neural Networks</span>"
    ]
  },
  {
    "objectID": "11_transformer.html",
    "href": "11_transformer.html",
    "title": "11  Transformers",
    "section": "",
    "text": "Coming soon.",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Transformers</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Quellenverzeichnis",
    "section": "",
    "text": "Ananthaswamy, Anil. 2024. Why Machines Learn: The Elegant Math\nBehind Modern AI. Dutton.\n\n\nGéron, Aurélien. 2022. Hands-on Machine Learning with Scikit-Learn,\nKeras, and TensorFlow: Concepts, Tools, and Techniques to Build\nIntelligent Systems. 3rd ed. O’Reilly.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani.\n2021. An Introduction to Statistical Learning: With Applications in\nr. 2nd ed. Springer. https://www.statlearning.com/.",
    "crumbs": [
      "Quellenverzeichnis"
    ]
  },
  {
    "objectID": "math.html",
    "href": "math.html",
    "title": "Anhang A — Mathe- und Statistik-Grundlagen",
    "section": "",
    "text": "A.1 Funktionen\nIn diesem Kapitel repetieren wir die wichtigsten Grundlagen aus der Mathematik und Statistik, die es braucht, um Machine Learning Modelle zu verstehen. Das Thema Lineare Algebra wird für die meisten von Ihnen wahrscheinlich Neuland sein.\nEine Funktion, die wir in der Mathematik typischerweise mit \\(f\\) bezeichnen, ordnet jedem Argument \\(x\\) aus dem Definitionsbereich \\(D\\) (engl. Domain) genau einen Wert \\(y\\) aus dem Wertebereich \\(W\\) (engl. Codomain) zu. Oft sind \\(D\\) und \\(W\\) die Menge der reellen Zahlen, also \\(\\mathbb{R}\\). Die Menge der reellen Zahlen enthält alle möglichen Zahlen, die Sie sich vorstellen können.1 Zum Beispiel die Zahlen \\(3\\), \\(-4.247\\), \\(\\sqrt{14}\\), \\(5/8\\), etc.\nWie eine Funktion grafisch aussieht, ist aus Panel (a) der Abbildung @ref(fig:functions) ersichtlich. Hier zeigen wir die Form einer Funktion in einem kartesischen Koordinatensystem. Die Funktionskurve weist jedem Wert \\(x\\) auf der x-Achse genau einen Wert \\(y\\) auf der y-Achse zu. Der wichtigste Teil der oben aufgeführten Definition ist der Teil “genau einen Wert”, denn eine Funktion kann einem Element \\(x\\) nicht zwei oder mehr Werte zuweisen, sondern nur genau einen. Genau aus diesem Grund handelt es sich bei Panel (b) in Abbildung @ref(fig:functions) nicht um eine Funktion, da gewissen \\(x\\)-Werten mehrere Werte \\(y\\) zugeordnet werden. Wichtig: das heisst aber nicht, dass zwei verschiedenen \\(x\\)-Werten, nennen wir sie \\(x'\\) und \\(x''\\), derselbe \\(y\\)-Wert zugeordnet werden kann (vgl. Panel (a)).\n(a) Eine Funktion, die jedem x-Wert genau einen y-Wert zuweist. (b) Keine Funktion.\nMathematisch wird diese allgemeine Definition einer Funktion häufig wie folgt beschrieben:\n\\[\nf : x \\mapsto y\n\\] Wir haben also eine Funktion \\(f\\), die jedem Element \\(x\\) genau einen Wert \\(y\\) zuweist. Der Pfeil in obiger mathematischer Schreibweise beschreibt genau dieses Mapping. Wie genau dieses Mapping einem Argument \\(x\\) den entsprechenden \\(y\\)-Wert zuordnet, wird durch die Funktion \\(f(x)\\) beschrieben. In den folgenden Abschnitten schauen wir uns typische Beispiele von Funktionen an, angefangen mit linearen Funktionen. Doch vorher wollen wir uns kurz überlegen, warum Funktionen für das Machine Learning überhaupt wichtig sind. Ein grosser Teil des Machine Learnings, der Supervised Learning genannt wird, befasst sich mit dem Problem, wie eine Zielvariable \\(y\\) mithilfe von einem oder mehreren Prädiktoren \\(x\\) vorhergesagt werden kann. Ein Machine Learning Modell ist darum nichts anderes als eine Funktion \\(y=f(x)\\), die basierend auf den Prädiktoren \\(x\\) die Zielvariable \\(y\\) möglichst gut beschreiben kann.2",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Mathe- und Statistik-Grundlagen</span>"
    ]
  },
  {
    "objectID": "math.html#funktionen",
    "href": "math.html#funktionen",
    "title": "Anhang A — Mathe- und Statistik-Grundlagen",
    "section": "",
    "text": "A.1.1 Lineare Funktionen\nNun schauen wir uns an, wie eine lineare Funktion aussieht. Eine lineare Funktion kann allgemein wie folgt geschrieben werden:\n\\[\ny = f(x) = a \\cdot x + b\n\\] Obige Funktionsgleichung besagt, dass wir den entsprechenden \\(y\\)-Wert kriegen, indem wir den Wert des Arguments \\(x\\) mit \\(a\\) multiplizieren und danach eine Konstante \\(b\\) addieren. \\(a\\) und \\(b\\) sind die Parameter dieser Funktion. Die konkreten Zahlenwerte dieser beiden Parameter definieren, wie die Funktion am Schluss genau aussieht.\nEine lineare Funktion hat auch eine geometrische Interpretation und zwar entspricht eine lineare Funktion einer Gerade. Das ist auch der Grund, warum wir diese Funktionen linear nennen, sie können graphisch durch eine “Linie” dargestellt werden. Der Parameter \\(a\\) ist die Steigung dieser Geraden und der Parameter \\(b\\) entspricht dem Ort, wo die Gerade die y-Achse schneidet (sogenannter y-Achsenabschnitt).\nAm besten schauen wir uns ein paar konkrete Beispiele an (Abb. @ref(fig:lin-func)).\n\n\n\n\n\nBeispiele linearer Funktionen.\n\n\n\n\n\n\n\nBeispiele linearer Funktionen.\n\n\n\n\nAus der linken Abbildung können wir ablesen, dass die Steigung dieser Geraden \\(\\frac{\\Delta y}{\\Delta x}=\\frac{2}{2}=1\\) ist und dass die Gerade die y-Achse am Ort \\(1\\) schneidet. Die entsprechende lineare Funktion kann dementsprechend als \\(y = x + 1\\) geschrieben werden.3\nAus der rechten Abbildung können wir ablesen, dass die Steigung \\(\\frac{\\Delta y}{\\Delta x}=\\frac{-1}{2}=-0.5\\) ist und dass die Gerade die y-Achse am Ort \\(-2\\) schneidet. Die entsprechende lineare Funktion kann dementsprechend als \\(y = -0.5\\cdot x -2\\) geschrieben werden.\nEs ist wichtig zu sehen, dass der Effekt einer Veränderung von \\(x\\) (also \\(\\Delta x\\)) auf \\(y\\) überall derselbe ist. Es spielt also keine Rolle, ob wir von \\(x=-2\\) zu \\(x=-1\\) gehen oder von \\(x=100\\) zu \\(x=101\\), die entsprechende Veränderung in \\(y\\) (also \\(\\Delta y\\)) wird dieselbe sein. Das muss so sein, denn die Gerade steigt (oder sinkt) mit konstanter Steigung.\n\nAufgaben\n\nZeichnen Sie die Funktion \\(y = 2\\cdot x\\) in ein Koordinatensystem ein. Warum fehlt der Parameter \\(b\\)?\nZeichnen Sie die Funktion \\(y=-3\\) in ein Koordinatensystem ein. Ist das überhaupt eine Funktion nach obiger Definition?\n\n\n\n\nA.1.2 Quadratische Funktionen\nNun wollen wir uns eine etwas interessantere (und flexiblere) Familie von Funktionen anschauen, nämlich quadratische Funktionen. Auch hier wollen wir die Funktion erstmal allgemein aufschreiben:\n\\[\ny = f(x) = a \\cdot x^2 + b \\cdot x + c\n\\] Eine quadratische Funktion hat drei Parameter, nämlich \\(a\\), \\(b\\) und \\(c\\). Grafisch entspricht die quadratische Funktion einer Parabel (vgl. Abb. @ref(fig:quad-func)). Die Parameter sind hier nicht mehr so einfach grafisch zu interpretieren, aber die vier Beispiele in unten stehender Abbildung geben Anhaltspunkte, was passiert, wenn die Parameterwerte sich ändern.\n\n\n\n\n\nBeispiele quadratischer Funktionen.\n\n\n\n\n\nAufgaben\n\nSie haben folgende quadratische Gleichung: \\(y = 2 \\cdot x^2 + x - 2\\). Berechnen Sie mit der bekannten Lösungsformel \\(x_{1,2}=\\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}\\) die Orte auf der x-Achse, wo die Parabel die Achse schneidet (oder einfacher gesagt die Nullstellen).\nVerwenden Sie folgenden R-Code, um beliebige quadratische Funktionen grafisch darzustellen, indem Sie die Parameterwerte auf der ersten Code-Zeile verändern.\n\n\n# Parameter setzen\na &lt;- 2; b &lt;- 0; c &lt;- 1\n# Quadratische Funktion\nquad &lt;- function(x, a, b, c) {a * x^2 + b * x + c}\n# x-Werte\nx &lt;- seq(-6, 6, 0.01)\n# y-Werte\ny &lt;- quad(x, a, b, c)\n# Plot\nplot(x, y, type = \"l\", lwd = 2, col = \"darkcyan\")\n\n\nSie wundern sich nun vielleicht, könnte man nicht auch eine Funktion antreffen, in der \\(x^3\\), \\(x^4\\), etc. vorkommen? Das ist selbstverständlich möglich. In diesem Fall spricht man dann von einem sogenannten Polynom. Die höchste Potenz des Arguments \\(x\\) definiert den Grad des Polynoms.\nSchauen wir uns doch am besten gleich wieder ein Beispiel an:\n\\[\ny = f(x) = 1 \\cdot x^4 - 2 \\cdot x^3 - 5 \\cdot x^2 + 8 \\cdot x - 2\n\\] Die Visualisierung dieser Funktion ist in Abb. @ref(fig:poly-func) gegeben. Diese Funktion ist nun bereits enorm flexibel und kann je nach Parameterwerten ganz unterschiedliche Zusammenhänge abbilden.\n\n\n\n\n\nBeispiel einer polynomischen Funktion vierten Grades.\n\n\n\n\n\nAufgaben\n\nEine quadratische Funktion ist ein Polynom welchen Grades?\nHandelt es sich bei der Funktion \\(y=2x^5 + x + 1\\) immer noch um ein Polynom? Falls ja, ein Polynom welchen Grades?\nHandelt es sich bei der Funktion \\(y = x^{0.5} + 2\\) um ein Polynom?\n\n\n\n\nA.1.3 Funktionen mehrerer Argumente\nBisher haben wir nur Funktionen mit einem Argument \\(x\\) angeschaut, doch die meisten für das Machine Learning interessanten Funktionen sind Funktionen mehrerer Argumente.\nDer Einfachheit halber schauen wir uns hier nur mal eine lineare Funktion zweier Argumente, nennen wir sie \\(x_1\\) und \\(x_2\\), an, denn diese können wir in 3D immer noch visualisieren. Wir betrachten folgende Funktion: \\(y = f(x_1,x_2) = 1 \\cdot x_1 + 0.5 \\cdot x_2 + 5\\).\n\n\n\n\n\nLineare Funktion zweier Argumente (Ebene).\n\n\n\n\nAha! Während eine lineare Funktion eines Arguments grafisch einer Gerade entspricht, sehen wir nun, dass eine lineare Funktion zweier Argumente nichts anderes als eine Ebene darstellt. Wir sehen, dass die Ebene die y-Achse am Punkt \\(5\\) schneidet. Etwas schwieriger zu sehen ist die Steigung der Ebene in die Richtung der \\(x_1\\)-Achse und in die Richtung der \\(x_2\\)-Achse. Sie können aber vielleicht bereits erraten, dass die (partiellen) Steigungen \\(1\\) und \\(0.5\\) betragen.\nDie Funktion ordnet jeden möglichen Punkt \\((x_1,x_2)\\) einem Punkt auf der Ebene zu. Wir können zum Beispiel für den in Abb. @ref(fig:plane) eingezeichneten Punkt \\((6,4)\\) den entsprechenden Punkt auf der Ebene ausrechnen:\n\\[ \\begin{split}\ny &= 1 \\cdot x_1 + 0.5 \\cdot x_2 + 5\\\\\n&= 1 \\cdot 6 + 0.5 \\cdot 4 + 5\\\\\n&= 13\n\\end{split}\\]\nSelbstverständlich könnten wir uns nun auch quadratische Funktionen oder Polynome mehrerer Argumente anschauen, aber darauf verzichten wir vorerst.\n\n\nA.1.4 Potenzen und Logarithmen\nBlabla…",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Mathe- und Statistik-Grundlagen</span>"
    ]
  },
  {
    "objectID": "math.html#integral--und-differentialrechnung",
    "href": "math.html#integral--und-differentialrechnung",
    "title": "Anhang A — Mathe- und Statistik-Grundlagen",
    "section": "A.2 Integral- und Differentialrechnung",
    "text": "A.2 Integral- und Differentialrechnung\nOlteanu materials: Local vs. global minima From a maximization to a minimization problem Basic definition of derivative Differentiation rules local min., max. and saddle point Second derivative test Partial derivatives What is a gradient? What is Hessian? What is Jacobian? Chain rules Lagrange optimization",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Mathe- und Statistik-Grundlagen</span>"
    ]
  },
  {
    "objectID": "math.html#lineare-algebra",
    "href": "math.html#lineare-algebra",
    "title": "Anhang A — Mathe- und Statistik-Grundlagen",
    "section": "A.3 Lineare Algebra",
    "text": "A.3 Lineare Algebra\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOlteanu materials: What is a scalar? What is a vector? What is a matrix? Vector norms Inner products Symmetric, diagonal, square and identity matrix Associative, commutative laws for matrices Matrix addition and multiplication Matrix inversion Eigenvectors and eigenvalues Quadratic form and positive (semi-) definiteness Differentiation rules for matrices",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Mathe- und Statistik-Grundlagen</span>"
    ]
  },
  {
    "objectID": "math.html#wahrscheinlichkeitsrechnung",
    "href": "math.html#wahrscheinlichkeitsrechnung",
    "title": "Anhang A — Mathe- und Statistik-Grundlagen",
    "section": "A.4 Wahrscheinlichkeitsrechnung",
    "text": "A.4 Wahrscheinlichkeitsrechnung\nOlteanu materials: Sample space and axioms of probability Conditional probability definition Discrete vs. continuous random variables Joint probability distributions Expectation and variance, covariance (always for discrete and continuous) Bernoulli, Binomial, Normal, Multivariate Normal, Laplace\n\nA.4.1 Diskrete Zufallsvariablen\nWir werden später sehen, dass im Machine Learning oftmals Dinge als Zufallsvariablen modelliert werden. Eine Zufallsvariable \\(X\\) ist eine Variable, für die der konkrete Wert nicht von vornherein klar ist. Wir können mit \\(X\\) zum Beispiel das Resultat eines Münzwurfs modellieren. Die zwei möglichen Resultate sind Kopf und Zahl. Vor dem Münzwurf ist nicht klar, ob Kopf oder Zahl erscheinen wird. Genau darum modellieren wir das Resultat des Münzwurfs als Zufallsvariable.\nEs gibt in diesem einfachen Beispiel nur zwei mögliche Resultate (Kopf und Zahl), d.h. die Anzahl möglicher Resultate ist endlich (= nicht unendlich). Darum handelt es sich in diesem Fall um eine diskrete Zufallsvariable.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Mathe- und Statistik-Grundlagen</span>"
    ]
  },
  {
    "objectID": "math.html#verteilungen",
    "href": "math.html#verteilungen",
    "title": "Anhang A — Mathe- und Statistik-Grundlagen",
    "section": "A.5 Verteilungen",
    "text": "A.5 Verteilungen",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Mathe- und Statistik-Grundlagen</span>"
    ]
  },
  {
    "objectID": "math.html#footnotes",
    "href": "math.html#footnotes",
    "title": "Anhang A — Mathe- und Statistik-Grundlagen",
    "section": "",
    "text": "Einzige Ausnahme sind die komplexen Zahlen.↩︎\nZumindest aus einer nicht-probabilistischen Perspektive.↩︎\nWir müssen hier die Steigung \\(1\\) nicht explizit schreiben, aber selbstverständlich ist es nicht falsch die lineare Funktion als \\(y = 1\\cdot x + 1\\) zu schreiben.↩︎",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Mathe- und Statistik-Grundlagen</span>"
    ]
  },
  {
    "objectID": "programming.html",
    "href": "programming.html",
    "title": "Anhang B — R und Python",
    "section": "",
    "text": "Coming soon.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>R und Python</span>"
    ]
  }
]